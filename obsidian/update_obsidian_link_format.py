"""
éœ€æ±‚ç›®æ ‡

å°† Markdown æ–‡ä»¶ä¸­å¼•ç”¨çš„æœ¬åœ°èµ„æºè·¯å¾„ï¼ˆå¦‚å›¾ç‰‡ã€æ–‡ä»¶ï¼‰è‡ªåŠ¨è½¬æ¢ä¸ºå¯é€šè¿‡ Web è®¿é—®çš„å¤–éƒ¨ URL æ ¼å¼ã€‚

å¤„ç† Obsidian æ–‡æ¡£ä¸­çš„é“¾æ¥æ ¼å¼èŒƒå›´ï¼š

1. Obsidian æ”¯æŒçš„ Wiki é“¾æ¥æ ¼å¼

- å½“å‰æ–‡ä»¶å†…é”šç‚¹é“¾æ¥ï¼š`[[#æ ‡é¢˜]]`     
- å½“å‰æ–‡ä»¶å†…å—æ ‡è¯†ç¬¦é“¾æ¥ï¼š`[[#^å—æ ‡è¯†ç¬¦]]`
- æ™®é€šæ–‡ä»¶é“¾æ¥ï¼š`[[assets/file1.md]]`
- æ”¯æŒæ–‡ä»¶å¸¦é”šç‚¹ï¼š`[[assets/file2.md#æ ‡é¢˜]]`
- æ”¯æŒæ–‡ä»¶å¸¦å—æ ‡è¯†ç¬¦ï¼š`[[assets/file3.md#^å—æ ‡è¯†ç¬¦]]`
- æ”¯æŒæ–‡ä»¶å¸¦åˆ«åï¼š`[[assets/file4.md|åˆ«å]]`
- æ”¯æŒæ–‡ä»¶å¸¦é”šç‚¹å’Œåˆ«åï¼š`[[assets/file5.md#æ ‡é¢˜|åˆ«å]]`
- æ”¯æŒæ–‡ä»¶å¸¦å—æ ‡è¯†ç¬¦å’Œåˆ«åï¼š`[[assets/file6.md#^å—æ ‡è¯†ç¬¦|åˆ«å]]`
- å›¾ç‰‡èµ„æºé“¾æ¥ï¼š`![[assets/image1.png]]`
- æ”¯æŒå›¾ç‰‡å¸¦å°ºå¯¸å£°æ˜ï¼š`![[assets/image2.png | 400x300]]`
- æ”¯æŒå›¾ç‰‡ä»…æŒ‡å®šå®½åº¦ï¼š`![[assets/image3.png | 400]]`

2. æ ‡å‡† Markdown é“¾æ¥æ ¼å¼

- å½“å‰æ–‡ä»¶å†…é”šç‚¹é“¾æ¥ï¼š`[åˆ«å](#æ ‡é¢˜)`
- æ™®é€šæ–‡ä»¶é“¾æ¥ï¼š`[åˆ«å](assets/file7.md)`
- æ”¯æŒæ–‡ä»¶å¸¦é”šç‚¹ï¼š`[åˆ«å](assets/file8.md#æ ‡é¢˜)`
- å›¾ç‰‡èµ„æºé“¾æ¥ï¼š`![æè¿°](assets/image4.png)`
- æ™®é€šèµ„æºé“¾æ¥æŒ‡å‘å›¾ç‰‡ï¼š`[æè¿°](assets/image5.png)`
   
3. Obsidian Markdown æ‰©å±•

- å½“å‰æ–‡ä»¶å†…é”šç‚¹åµŒå…¥ï¼š`![åˆ«å](#æ ‡é¢˜)`
- å½“å‰æ–‡ä»¶å†…å—æ ‡è¯†ç¬¦åµŒå…¥`![åˆ«å](#^å—æ ‡è¯†ç¬¦)`
- å½“å‰æ–‡ä»¶å†…å—æ ‡è¯†ç¬¦é“¾æ¥ï¼š`[åˆ«å](#^å—æ ‡è¯†ç¬¦)`
- æ”¯æŒæ–‡ä»¶å¸¦å—æ ‡è¯†ç¬¦ï¼š`[åˆ«å](assets/file9.md#^å—æ ‡è¯†ç¬¦)`
- æ”¯æŒå›¾ç‰‡å¸¦å°ºå¯¸å£°æ˜ï¼š`![400x300](assets/image6.png)`
- æ”¯æŒå›¾ç‰‡å¸¦æè¿°å’Œå°ºå¯¸å£°æ˜ï¼š`![æè¿° | 400x300](assets/image7.png)`
- æ”¯æŒå›¾ç‰‡å¸¦æè¿°å’Œä»…å®½åº¦å£°æ˜ï¼š`![æè¿° | 400](assets/image8.png)`

4. Obsidian ç‰¹æ®ŠåµŒå…¥æ ¼å¼

- å½“å‰æ–‡ä»¶å†…é”šç‚¹åµŒå…¥ï¼š`![[#æ ‡é¢˜]]`
- å½“å‰æ–‡ä»¶å†…å—æ ‡è¯†ç¬¦åµŒå…¥ï¼š`![[#^å—æ ‡è¯†ç¬¦]]`
- åµŒå…¥æ–‡ä»¶å†…å®¹ï¼š`![[assets/file10.md]]`
- åµŒå…¥ PDF é¡µé¢æŒ‡å®šé¡µæ•°ï¼š`![[assets/doc.pdf#page=3]]`

5. è¡¥å……ï¼š

- ![æè¿°](http://example.com/image.png)
- ![æè¿°](https://example.com/audio.mp3)
- ![æè¿°|400x300](assets/image%20copy.png)

å¤„ç†è¯´æ˜:

- å°†æ‰€æœ‰æœ¬åœ°èµ„æºè·¯å¾„è½¬æ¢ä¸ºå¤–éƒ¨ URL æ ¼å¼ï¼Œå¹¶ä¿ç•™åŸå§‹é“¾æ¥çš„åˆ«åå’Œæè¿°ã€‚
- åµŒå…¥å›¾ç‰‡é“¾æ¥ï¼Œç”ŸæˆåµŒå…¥å¼å›¾ç‰‡çš„ HTMLï¼Œå¯ä¿ç•™åŸå§‹é“¾æ¥çš„æè¿°å’Œå°ºå¯¸å£°æ˜ã€‚
- éåµŒå…¥å›¾ç‰‡é“¾æ¥ï¼Œç”Ÿæˆå›¾ç‰‡çš„ Markdown é“¾æ¥ï¼Œå¯ä¿ç•™åŸå§‹é“¾æ¥çš„æè¿°ã€‚
- æ™®é€šæ–‡ä»¶é“¾æ¥ï¼Œç”Ÿæˆæ–‡ä»¶çš„ Markdown é“¾æ¥ï¼Œå¯ä¿ç•™åŸå§‹é“¾æ¥çš„é”šç‚¹æ ‡é¢˜å’Œåˆ«åï¼Œä½†ä¸ä¿ç•™å—æ ‡è¯†ç¬¦ã€‚

"""
import os
import shutil
import re
from urllib.parse import quote
import sys
from pathlib import Path
import logging

import argparse
import subprocess
import shlex
from typing import Optional

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
logger = logging.getLogger('ObsidianLinkConverter')

# é…ç½®è·¯å¾„
source_folder = "Default"
source_note_dir = fr'D:\Obsidian\Middle\Default'
target_note_dir = fr'D:\Obsidian\Middle\obsidianlinks'
# external_link_prefix = r'https://raw.githubusercontent.com/littlekj/linkres/master/obsidian/'
external_link_prefix = '/'  # ç›¸å¯¹åœ°å€å‰ç¼€æ·»åŠ  / ç”Ÿæˆç»å¯¹è·¯å¾„ï¼Œæ‹¼æ¥ GitHub ä»“åº“åœ°å€ä¾¿äº Web è®¿é—®
# external_link_prefix = ''

# å®šä¹‰æ‰€æœ‰æ”¯æŒçš„æ–‡ä»¶ç±»å‹ï¼ˆæ‰©å±•åˆ—è¡¨ï¼‰
supported_extensions = {
    'image': ['png', 'jpg', 'jpeg', 'gif', 'bmp', 'tiff', 'webp', 'svg'],
    'document': ['pdf', 'doc', 'docx', 'xls', 'xlsx', 'ppt', 'pptx', 'txt', 'md'],
    'audio': ['mp3', 'wav', 'ogg', 'flac', 'm4a'],
    'video': ['mp4', 'mov', 'avi', 'mkv', 'webm'],
    'archive': ['zip', 'rar', '7z', 'tar', 'gz']
}

# æ„å»ºæ‰€æœ‰æ‰©å±•åçš„æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼
all_extensions = []
for category in supported_extensions.values():
    all_extensions.extend(category)
    
# å…¨å±€èµ„æºç¼“å­˜ï¼ˆé¿å…é‡å¤æŸ¥æ‰¾ï¼‰
resource_cache = {}


# åªåœ¨ Windows å¹³å°å¯¼å…¥ pywin32 æ¨¡å—
if os.name == 'nt':
    try:
        import win32file
        import pywintypes
    except ImportError:
        print("è¯·å®‰è£… pywin32 åº“ä»¥ä¿®å¤ç›®å½•çš„æ—¶é—´æˆ³")  


def fix_directory_timestamps(src_dir: str, dst_dir: str):
    """
    ä¿®å¤ Windows ä¸‹ç›®æ ‡ç›®å½•æ—¶é—´æˆ³ï¼ˆåˆ›å»ºã€ä¿®æ”¹ã€è®¿é—®ï¼‰
    """
    if not os.path.exists(dst_dir):
        print(f"æ— æ³•ä¿®å¤æ—¶é—´æˆ³ï¼šç›®æ ‡ç›®å½•ä¸å­˜åœ¨ {dst_dir}")
        return

    try:
        src_stat = os.stat(src_dir)
        ctime = pywintypes.Time(src_stat.st_ctime)
        atime = pywintypes.Time(src_stat.st_atime)
        mtime = pywintypes.Time(src_stat.st_mtime)

        handle = win32file.CreateFile(
            dst_dir,
            win32file.GENERIC_WRITE,
            win32file.FILE_SHARE_READ | win32file.FILE_SHARE_WRITE,
            None,
            win32file.OPEN_EXISTING,
            win32file.FILE_FLAG_BACKUP_SEMANTICS,  # ç”¨äºæ“ä½œç›®å½•
            None
        )
        try:
            win32file.SetFileTime(handle, ctime, atime, mtime)
        finally:
            handle.close()
    except Exception as e:
        print(f"ä¿®å¤ç›®å½•æ—¶é—´æˆ³å¤±è´¥ {dst_dir}: {e}")


def robocopy_copy(src: str, dst: str) -> bool:
    """
    Windows ç³»ç»Ÿä¸‹ä½¿ç”¨ robocopy å¤åˆ¶æ–‡ä»¶æˆ–ç›®å½•ï¼Œä¿ç•™æ—¶é—´æˆ³ï¼ˆåˆ›å»ºã€ä¿®æ”¹ã€è®¿é—®ï¼‰
    :param src: æºæ–‡ä»¶æˆ–ç›®å½•è·¯å¾„
    :param dst: ç›®æ ‡è·¯å¾„ï¼ˆæ–‡ä»¶æˆ–ç›®å½•ï¼‰
    """
    if not os.path.exists(src):
        raise FileNotFoundError(f"æºè·¯å¾„ä¸å­˜åœ¨: {src}")

    is_file = os.path.isfile(src)
    
    # å¦‚æœç›®æ ‡æ˜¯æ–‡ä»¶ä¸”æºæ˜¯æ–‡ä»¶ï¼Œrobocopy ä¸æ”¯æŒï¼Œéœ€åå¤„ç†
    dst_is_file = (
        not dst.endswith(os.sep) and
        os.path.splitext(dst)[1] != '' and
        not os.path.isdir(dst)
    )
    
    if is_file:
        parent_src = os.path.dirname(src)
        parent_dst = os.path.dirname(dst) if dst_is_file else dst
        file_list = [os.path.basename(src)]
    else:
        parent_src = src
        parent_dst = dst
        file_list = []

    # åˆ›å»ºç›®æ ‡çˆ¶ç›®å½•
    os.makedirs(parent_dst, exist_ok=True)

    # ä¼˜å…ˆä½¿ç”¨ shell=False + åˆ—è¡¨
    # æ„å»º robocopy å‘½ä»¤
    cmd = [
        "robocopy",
        parent_src,
        parent_dst,
        *file_list,
        "/COPY:DAT",     # å¤åˆ¶æ•°æ®ã€å±æ€§ã€æ—¶é—´æˆ³
        "/DCOPY:T",      # å¤åˆ¶ç›®å½•æ—¶é—´æˆ³ï¼ˆåˆ›å»ºã€ä¿®æ”¹ã€è®¿é—®ï¼‰
        # "/E",            # åŒ…å«å­ç›®å½•ï¼ˆå«ç©ºç›®å½•ï¼‰
        "/R:0", "/W:0",  # ä¸é‡è¯•
        "/NFL", "/NDL",  # ä¸è¾“å‡ºæ–‡ä»¶å’Œç›®å½•
        "/NJH", "/NJS",  # æ— ä½œä¸šå¤´å’Œå°¾
        "/NC", "/NS",    # ä¸è¾“å‡ºæ–‡ä»¶å¤§å°ã€æ‘˜è¦
        "/IS",           # å¤åˆ¶ç›¸åŒæ–‡ä»¶ï¼ˆä¸è·³è¿‡ï¼‰
        "/IT"            # å¤åˆ¶ç›¸åŒæ–‡ä»¶çš„æ—¶é—´æˆ³ï¼ˆå³ä½¿æ•°æ®æ²¡å˜ï¼‰
    ]

    if not is_file:
        cmd.append("/E")  # åŒ…å«å­ç›®å½•ï¼ˆå«ç©ºç›®å½•ï¼‰

    try:
        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            timeout=300,    # 5åˆ†é’Ÿè¶…æ—¶
            shell=False     # é¿å… shell æ³¨å…¥
            # shell=True      # æ”¯æŒå†…å»ºå‘½ä»¤å’Œå˜é‡æ›¿æ¢
        )

        # robocopy è¿”å›ç ï¼š0~7 æˆåŠŸï¼Œ8+ å¤±è´¥
        # 0: æ— å¤åˆ¶ï¼ˆæ–‡ä»¶å·²æœ€æ–°ï¼‰
        # 1: æˆåŠŸå¤åˆ¶æ–‡ä»¶
        # 2: æœ‰é¢å¤–æ–‡ä»¶
        # 3: 1+2
        # 8+: ä¸¥é‡é”™è¯¯
        success = result.returncode < 8

        # è¾“å‡ºæ—¥å¿—
        if result.stdout.strip():
            print("=== robocopy è¾“å‡º ===\n" + result.stdout)
        if result.stderr.strip():
            print("=== robocopy é”™è¯¯ ===\n" + result.stderr)

        if success:
            # å¦‚æœç›®æ ‡æ˜¯æ–‡ä»¶ï¼Œrobocopy å®é™…å¤åˆ¶åˆ°äº†ç›®æ ‡ç›®å½•ï¼Œæ›¿æ¢æˆç›®æ ‡æ–‡ä»¶å
            if is_file and dst_is_file:
                temp_path = os.path.join(parent_dst, os.path.basename(src))
                if os.path.exists(temp_path):
                    os.replace(temp_path, dst)
            # ä¿®å¤ç›®å½•æ—¶é—´æˆ³
            if os.path.isdir(dst) and os.path.isdir(src):
                fix_directory_timestamps(src, dst)
        else:
            print(f"å¤åˆ¶å¤±è´¥ï¼ˆè¿”å›ç : {result.returncode}")

        return success

    except subprocess.TimeoutExpired:
        print("robocopy æ‰§è¡Œè¶…æ—¶")
        return False
    except Exception as e:
        print(f"robocopy æ‰§è¡Œå¤±è´¥: {e}")
        return False


def remote_path_type(user_host: str, remote_path: str) -> Optional[str]:
    """
    æ£€æŸ¥è¿œç¨‹è·¯å¾„ç±»å‹
    :return: 'file', 'directory', 'link', 'not_exists', None(æ‰§è¡Œå¤±è´¥)
    """
    quoted = shlex.quote(remote_path)
    check_cmd = (
        f"if [ -d {quoted} ]; then echo 'directory'; "
        f"elif [ -f {quoted} ]; then echo 'file'; "
        f"elif [ -L {quoted} ]; then echo 'link'; "
        f"else echo 'not_exists'; fi"
    )
    cmd = ["ssh", user_host, check_cmd]
    try:
        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            timeout=10,
            encoding='utf-8',
            errors='replace'
        )
        out = result.stdout.strip()
        if out in ('file', 'directory', 'link', 'not_exists'):
            return out
        return None
    except Exception as e:
        print(f"SSH æ£€æŸ¥å¤±è´¥: {e}")
        return None


def ensure_remote_dir(user_host: str, remote_path: str) -> bool:
    """é€šè¿‡ SSH ç¡®ä¿è¿œç¨‹ç›®å½•å­˜åœ¨"""
    cmd = ["ssh", user_host, f"mkdir -p {shlex.quote(remote_path)}"]
    try:
        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            encoding='utf-8',
            errors='replace'
        )
        return result.returncode == 0
    except Exception as e:
        print(f"åˆ›å»ºè¿œç¨‹ç›®å½•å¤±è´¥: {e}")
        return False


def rsync_copy(src: str, dst: str) -> bool:
    """
    Unix ç³»ç»Ÿï¼Œä½¿ç”¨ rsync å¤åˆ¶ä¿ç•™ä¿®æ”¹ã€è®¿é—®æ—¶é—´æˆ³
    æ”¯æŒï¼šæœ¬åœ°åˆ°æœ¬åœ°ã€æœ¬åœ°åˆ°è¿œç¨‹çš„å¤åˆ¶
    :param src: æºæ–‡ä»¶æˆ–ç›®å½•è·¯å¾„
    :param dst: ç›®æ ‡è·¯å¾„ï¼ˆæ–‡ä»¶æˆ–ç›®å½•ï¼‰ï¼Œæ”¯æŒ user@host:/path
    """
    if not os.path.exists(src):
        raise FileNotFoundError(f"æºè·¯å¾„ä¸å­˜åœ¨: {src}")

    src_path = src.rstrip('/') + '/' if os.path.isdir(src) else src

    # æ£€æŸ¥æ˜¯å¦æ˜¯è¿œç¨‹è·¯å¾„
    # is_remote = '@' in dst and ':' in dst
    # ä½¿ç”¨æ­£åˆ™è§£æè¿œç¨‹è·¯å¾„ï¼ˆæ”¯æŒ IPv6ï¼‰
    remote_match = r'^((?P<user>[^@]+)@)?(?P<host>\[[^\]]+\]|[^:]+):(?P<path>/.*)$'
    match = re.match(remote_match, dst)
    is_remote = bool(match)

    if is_remote:
        user = match.group('user') or ''
        host = match.group('host')
        user_host = f"{user}@{host}" if user else host
        remote_path = match.group('path').rstrip('/')
        remote_type = remote_path_type(user_host, remote_path)

        if remote_type is None:
            raise RuntimeError(f"æ— æ³•ç¡®å®šè¿œç¨‹è·¯å¾„ç±»å‹ï¼š{dst}")

        if os.path.isdir(src):
            # å¦‚æœæºæ˜¯ç›®å½•ï¼Œåˆ™ç›®æ ‡è·¯å¾„è¦ç¡®ä¿æ˜¯ç›®å½•
            if remote_type in ("directory", "link"):
                final_dst = f"{user_host}:{remote_path}/"
            elif remote_type == 'not_exists':
                ensure_remote_dir(user_host, remote_path)
                final_dst = f"{user_host}:{remote_path}/"
            else:
                raise RuntimeError(f"æºæ˜¯ç›®å½•ï¼Œç›®æ ‡ä¸èƒ½æ˜¯æ–‡ä»¶: {dst}")
        else:  # æºæ˜¯æ–‡ä»¶
            bname = os.path.basename(src)
            if remote_type == 'not_exists':
                if dst.endswith('/') or os.path.splitext(remote_path)[1] == '':
                    # ç›®æ ‡æ˜¯ç›®å½•
                    target_dir = remote_path.rstrip('/')
                    ensure_remote_dir(user_host, target_dir)
                    final_dst = f"{user_host}:{target_dir}/{bname}"
                else:
                    parent_remote = os.path.dirname(remote_path)
                    if parent_remote.strip('/') != "":  # é¿å…æ ¹ç›®å½•
                        ensure_remote_dir(user_host, parent_remote)
                    final_dst = f"{user_host}:{remote_path}"
            elif remote_type == 'directory':
                final_dst = f"{user_host}:{remote_path}/{bname}"
            else:
                final_dst = f"{user_host}:{remote_path}"
    else:
        if os.path.isdir(src):
            # æºæ˜¯ç›®å½•ï¼Œç›®æ ‡è·¯å¾„è¦ç¡®ä¿æ˜¯ç›®å½•
            final_dst = dst.rstrip("/") + "/"
            os.makedirs(final_dst, exist_ok=True)
        else:
            # æºæ˜¯æ–‡ä»¶ï¼Œç›®æ ‡è·¯å¾„åˆ¤æ–­
            if dst.endswith('/') or os.path.splitext(dst)[1] == '':
                dst = dst.rstrip('/')
                final_dst = os.path.join(dst, os.path.basename(src))
            else:
                final_dst = dst
            os.makedirs(os.path.dirname(final_dst), exist_ok=True)

    # æ„å»º rsync å‘½ä»¤
    cmd = ["rsync", "-a", "--atimes", src_path, final_dst]
    try:
        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            encoding='utf-8',
            errors='replace',
            timeout=300
        )
        if result.returncode == 0:
            return True

        outerr = result.stderr.lower()

        if "permission denied" in outerr or "rsync error" in outerr:
            cmd_sudo = ["sudo"] + cmd
            try:
                result2 = subprocess.run(
                    cmd_sudo,
                    capture_output=True,
                    text=True,
                    encoding='utf-8',
                    errors='replace',
                    timeout=300
                )
                return result2.returncode == 0
            except Exception:
                pass
        print("rsync å¤±è´¥:", result.stderr.strip())
        return False

    except subprocess.TimeoutExpired:
        print("rsync æ‰§è¡Œè¶…æ—¶")
        return False
    except FileNotFoundError:
        print("æœªæ‰¾åˆ° rsyncï¼Œå›é€€åˆ° shutil.copy2")
        return fallback_copy(src, dst)
    except Exception as e:
        print(f"rsync å¤åˆ¶å¤±è´¥: {e}")
        return False


def fallback_copy(src: str, dst: str) -> bool:
    """å›é€€å¤åˆ¶æ–¹æ¡ˆï¼ˆä½¿ç”¨ shutil.copy2ï¼Œä¿ç•™åŸºæœ¬æ—¶é—´æˆ³ï¼‰"""
    try:
        if os.path.isdir(src):
            if os.path.exists(dst):
                shutil.rmtree(dst)
            shutil.copytree(src, dst, copy_function=shutil.copy2)
        else:
            os.makedirs(os.path.dirname(dst), exist_ok=True)
            shutil.copy2(src, dst)
        return True
    except Exception as e:
        print(f"å›é€€å¤åˆ¶å¤±è´¥: {e}")
        return False


def copy_with_timestamps(src: str, dst: str) -> bool:
    """ç»Ÿä¸€æ¥å£ï¼šå¤åˆ¶å¹¶ä¿ç•™æ—¶é—´æˆ³"""
    if os.name == 'nt':  # Windows 
        return robocopy_copy(src, dst)
    else:  # Unix/Linux/macOS
        return rsync_copy(src, dst)
    

def copy_files_with_timestamps(source_note_dir, ignored_extensions=None):
    """å¤åˆ¶æºç›®å½•ä¸­æ‰€æœ‰æ–‡ä»¶åˆ°ç›®æ ‡ï¼Œå¹¶ä¿ç•™åŸå§‹æ—¶é—´æˆ³"""
    # try:
    #     from copy_with_timestamps import copy_with_timestamps
    # except ImportError:
    #     logger.error("æ— æ³•å¯¼å…¥ copy_with_timestamps æ¨¡å—ï¼Œè¯·ç¡®ä¿æ¨¡å—å­˜åœ¨ã€‚")
    
    ignored_extensions = ignored_extensions or []
    for item in os.listdir(source_note_dir):
        source_path = os.path.join(source_note_dir, item)
        if item.startswith('.') and os.path.isfile(source_path):
            # éšè—æ–‡ä»¶å¤åˆ¶æ—¶ï¼Œä¸åœ¨å¤åˆ¶å‘½ä»¤çš„ç›®æ ‡è·¯å¾„ä¸­æŒ‡å®šæ–‡ä»¶
            destination_path = os.path.join(target_note_dir)
            # print("destination_path", destination_path)
        else:
            destination_path = os.path.join(target_note_dir, item)
        
        # è·³è¿‡å¿½ç•¥çš„æ–‡ä»¶ç±»å‹
        if any(source_path.endswith(ext) for ext in ignored_extensions):
            continue
        
        if os.path.isdir(source_path):
            copy_with_timestamps(source_path, destination_path)
            logger.info(f"å¤åˆ¶ç›®å½•ï¼š{source_path} -> {destination_path}")
        else:
            copy_with_timestamps(source_path, destination_path)
            logger.info(f"å¤åˆ¶æ–‡ä»¶ï¼š{source_path} -> {destination_path}")


# åŒ¹é…å†…è”ä»£ç  å’Œ å¤šè¡Œä»£ç å—ï¼ˆåå¼•å·/æ³¢æµªå·ï¼Œ3ä¸ªæˆ–ä»¥ä¸Šï¼‰
# æ”¹è¿›çš„æ­£åˆ™ï¼šä¸ºæ¯ç§æƒ…å†µè®¾ç½®æ•è·ç»„ï¼Œå¹¶ç¡®ä¿å†…å®¹è¢«æ•è·
CODE_PATTERN = re.compile(
    r'(`[^`]+?`)'                                  # group 1: å†…è”ä»£ç 
    r'|(~{3,})([a-zA-Z][\w-]*)?\s*\n'              # group 2: æ³¢æµªå·å¼€å§‹, group 3: è¯­è¨€
    r'([\s\S]*?)\n'                                # group 4: æ³¢æµªå·å†…å®¹
    r'(~{3,})(?=\n|$)'                             # group 5: æ³¢æµªå·ç»“æŸ
    r'|(`{3,})([a-zA-Z][\w-]*)?\s*\n'              # group 6: åå¼•å·å¼€å§‹, group 7: è¯­è¨€
    r'([\s\S]*?)\n'                                # group 8: åå¼•å·å†…å®¹
    r'(`{3,})(?=\n|$)',                            # group 9: åå¼•å·ç»“æŸ
    re.MULTILINE
)


def save_code_blocks(content):
    code_blocks = []
    placeholder_counter = 0

    def replace_func(match):
        nonlocal placeholder_counter
        placeholder_counter += 1
        placeholder = f"__CODE_BLOCK_{placeholder_counter}__"

        if match.group(1):  # å†…è”ä»£ç 
            code = match.group(1)
        elif match.group(2):  # æ³¢æµªå·ä»£ç å—
            start_delim = match.group(2)   # ~~~
            lang = match.group(3) or ""    # å¯é€‰è¯­è¨€
            body = match.group(4)
            end_delim = match.group(5)     # ~~~
            # ä¿ç•™è¯­è¨€æ ‡è¯†
            code = f"{start_delim}{lang}\n{body}\n{end_delim}"
        else:  # åå¼•å·ä»£ç å—
            start_delim = match.group(6)   # ```
            lang = match.group(7) or ""    # å¯é€‰è¯­è¨€
            body = match.group(8)
            end_delim = match.group(9)     # ```
            # ä¿ç•™è¯­è¨€æ ‡è¯†
            code = f"{start_delim}{lang}\n{body}\n{end_delim}"

        code_blocks.append((placeholder, code))
        return placeholder

    new_content = CODE_PATTERN.sub(replace_func, content)
    return new_content, code_blocks


def restore_code_blocks(content, code_blocks):
    """
    å°†å ä½ç¬¦æ›¿æ¢å›åŸå§‹ä»£ç å—
    """
    for placeholder, code in code_blocks:
        content = content.replace(placeholder, code)
    return content

    
# Wiki é“¾æ¥æ­£åˆ™ï¼ˆæ”¯æŒè·¯å¾„/æ ‡é¢˜/å—/å°ºå¯¸/åˆ«åï¼Œç«–çº¿å‰åå¯æœ‰ç©ºæ ¼ï¼‰
wiki_link_regex = r"""
    (!?)                           # 1: å¯é€‰ "!"ï¼ˆembedï¼‰
    \[\[
        (?:([^\]\|\n#^]+?)\s*)?    # 2: è·¯å¾„ï¼ˆå¯é€‰ï¼Œè‡ªåŠ¨å»æ‰å°¾ç©ºæ ¼ï¼‰
        (?:\#(?:
            (?!\^)([^\]\|\n#^]+)   # 3: æ ‡é¢˜ï¼ˆ#xxxï¼‰
          | \^([^\]\|\n#]+)        # 4: å—æ ‡è¯†ç¬¦ï¼ˆ#^xxxï¼‰
        ))?
        (?:\s*\|\s*(\d{1,4}(?:x\d{1,4})?))?   # 5: å°ºå¯¸ï¼ˆ400 æˆ– 400x300ï¼‰
        (?:\s*\|\s*([^\]\n|]+))?              # 6: åˆ«å
    \]\]
"""

# Markdown é“¾æ¥æ­£åˆ™ï¼ˆæ”¯æŒè·¯å¾„/æ ‡é¢˜/å—/å°ºå¯¸ï¼Œæè¿°å»æ‰å°¾ç©ºæ ¼ï¼‰
markdown_link_regex = r"""
    (!)?                           # 1: å¯é€‰ "!"ï¼ˆembedï¼‰
    \[
        ([^\]\|\n]*?)\s*           # 2: æè¿°/åˆ«åï¼ˆå»å°¾ç©ºæ ¼ï¼‰
        (?:\s*\|\s*
            (\d{1,4}(?:x\d{1,4})?) # 3: å°ºå¯¸ï¼ˆ400 æˆ– 400x300ï¼‰
        )?
    \]
    \(
        ([^()\n#^]+?)?             # 4: è·¯å¾„ï¼ˆå¯é€‰ï¼‰
        (?:\#(?:
            (?!\^)([^()\n#^]+)     # 5: æ ‡é¢˜ï¼ˆ#xxxï¼‰
          | \^([^()\n#]+)          # 6: å—æ ‡è¯†ç¬¦ï¼ˆ#^xxxï¼‰
        ))?
    \)
"""

wiki_link_pattern = re.compile(wiki_link_regex, re.VERBOSE)
markdown_link_pattern = re.compile(markdown_link_regex, re.VERBOSE)


# def is_image(path: str) -> bool:
#     """åˆ¤æ–­æ˜¯å¦ä¸ºå›¾ç‰‡é“¾æ¥"""
#     extensions_with_dot = tuple(f'.{ext}' for ext in IMAGE_EXT)
#     return path.lower().endswith(extensions_with_dot)


def parse_desc_size(raw_desc_or_size, size_group):
    """è§£æå›¾ç‰‡æè¿°å’Œå°ºå¯¸"""
    if not size_group:
        if raw_desc_or_size and re.match(r'^\d{1,4}(?:x\d{1,4})?$', raw_desc_or_size):
            return None, raw_desc_or_size
        return raw_desc_or_size, None

    return raw_desc_or_size, size_group


def extract_wiki_links(text):
    """Obsidian Wiki é“¾æ¥è§£æ"""
    matches = []
    for match in wiki_link_pattern.finditer(text):
        # isImage = is_image(match.group(2))
        # if isImage:
        #     print("image_path:", match.group(2))
        full_match = match.group(0)
        # print("full_match:", full_match)
        embed = bool(match.group(1))
        path = match.group(2)
        title = match.group(3)
        block_id = match.group(4)
        desc = match.group(6)
        size = match.group(5)
        if desc and size:
                desc = 'a' + desc + 'b'
                size = 'c' + size + 'd'
                
        matches.append({
            'full_match': full_match,
            'type': 'wiki',
            'embed': embed,
            'path': path,
            'title': title,
            'block_id': block_id,
            'desc': desc,
            'size': size,
            'start': match.start(),
            'end': match.end(),
        })

    return matches


def extract_markdown_links(text):
    """Obsidian Markdown é“¾æ¥è§£æ"""
    matches = []
    for match in markdown_link_pattern.finditer(text):
        # print("match.groups():", match.groups())
        full_match = match.group(0)
        embed = bool(match.group(1))
        raw_desc_or_size = match.group(2)
        size_group = match.group(3)
        path = match.group(4)
        desc, size = parse_desc_size(raw_desc_or_size, size_group)
        title = match.group(5)
        block_id = match.group(6)
        
        matches.append({
            'full_match': full_match,
            'type': 'markdown',
            'embed': embed,
            'path': path,
            'title': title,
            'block_id': block_id,
            'desc': desc,
            'size': size,
            'start': match.start(),
            'end': match.end(),
        })

    return matches


def confirm_delete(path):
    """ç¡®è®¤æ˜¯å¦åˆ é™¤æŒ‡å®šè·¯å¾„"""
    confirm = input(f"âš ï¸  ç¡®è®¤åˆ é™¤å†…å®¹ï¼š{path}ï¼Ÿ(y/N): ").strip().lower()
    return confirm == 'y'    

def remove_if_exists(path):
    """åˆ é™¤æ–‡ä»¶æˆ–ç›®å½•ï¼Œå¦‚æœå­˜åœ¨"""
    if os.path.exists(path):
        if os.path.isfile(path):
            os.remove(path)
        elif os.path.isdir(path):
            shutil.rmtree(path)
        logger.info(f"å·²åˆ é™¤: {path}")

def safe_remove_if_exists(path):
    """å®‰å…¨åˆ é™¤ç›®å½•ï¼Œå…ˆç¡®è®¤å†æ‰§è¡Œ"""
    if confirm_delete(path):
        remove_if_exists(path)
    else:
        print("âŒ å·²å–æ¶ˆåˆ é™¤æ“ä½œã€‚") 
        sys.exit(1)  # ç«‹å³é€€å‡ºç¨‹åº


def copy_files(source_note_dir, ignored_extensions=None):
    """å¤åˆ¶æºç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶åˆ°ç›®æ ‡ç›®å½•"""
    ignored_extensions = ignored_extensions or []
    for item in os.listdir(source_note_dir):
        source_path = os.path.join(source_note_dir, item)
        destination_path = os.path.join(target_note_dir, item)

        # è·³è¿‡å¿½ç•¥çš„æ–‡ä»¶ç±»å‹
        if any(source_path.endswith(ext) for ext in ignored_extensions):
            continue

        # # è·³è¿‡ç‰¹å®šç³»ç»Ÿæ–‡ä»¶
        # if item.startswith('.') or item in ['Thumbs.db', 'desktop.ini']:
        #     continue

        if os.path.isdir(source_path):
            shutil.copytree(source_path, destination_path, dirs_exist_ok=True)
            logger.info(f"å¤åˆ¶ç›®å½•: {source_path} -> {destination_path}")
        else:
            shutil.copy2(source_path, destination_path)
            logger.info(f"å¤åˆ¶æ–‡ä»¶: {source_path} -> {destination_path}")


def get_ignore_list(target_dir):
    """è·å–å¿½ç•¥æ–‡ä»¶åˆ—è¡¨"""
    ignore_files_path = os.path.join(target_dir, '.gitignore')
    if not os.path.exists(ignore_files_path):
        return []

    ignored = []
    with open(ignore_files_path, 'r', encoding='utf-8', newline='') as f:
        for line in f:
            stripped_line = line.strip()
            if stripped_line and not stripped_line.startswith('#'):
                # å¤„ç†ç›®å½•å¿½ç•¥ï¼ˆç§»é™¤ç»“å°¾çš„/ï¼‰
                if stripped_line.endswith('/'):
                    stripped_line = stripped_line[:-1]
                ignored.append(stripped_line)
    return ignored


def find_resource_file(source_dir, resource_path, current_note_dir):
    """
    åœ¨ä»“åº“ä¸­æŸ¥æ‰¾èµ„æºæ–‡ä»¶
    :param source_dir: ä»“åº“æ ¹ç›®å½•
    :param resource_path: èµ„æºè·¯å¾„ï¼ˆå¯èƒ½åŒ…å«ç›¸å¯¹è·¯å¾„ï¼‰
    :param current_note_dir: å½“å‰ç¬”è®°æ‰€åœ¨ç›®å½•
    :return: åŸºäºä»“åº“æ ¹ç›®å½•çš„ç›¸å¯¹è·¯å¾„ï¼Œå¦‚æœæ‰¾ä¸åˆ°è¿”å›None
    """
    # è½¬æ¢URLç¼–ç çš„ç©ºæ ¼ä¸ºæ™®é€šç©ºæ ¼
    resource_path = decode_url_space_only(resource_path)

    # æ£€æŸ¥ç¼“å­˜
    cache_key = (resource_path, current_note_dir)
    if cache_key in resource_cache:
        return resource_cache[cache_key]

    # å°è¯•å¯èƒ½çš„è·¯å¾„ç»„åˆ
    possible_paths = []

    # ç›¸å¯¹äºå½“å‰ç¬”è®°çš„è·¯å¾„
    relative_to_note = os.path.join(current_note_dir, resource_path)
    possible_paths.append(relative_to_note)
    
    # ç›¸å¯¹äºä»“åº“æ ¹ç›®å½•çš„è·¯å¾„
    relative_to_root = os.path.join(source_dir, resource_path)
    possible_paths.append(relative_to_root)
    
    # å°è¯•è§£æç»å¯¹è·¯å¾„ï¼ˆä»¥ / å¼€å¤´ï¼‰
    if resource_path.startswith('/'):
        abs_path = os.path.abspath(os.path.join(source_dir, resource_path[1:]))
        possible_paths.append(abs_path)
        
    # å°è¯•è§£æç›¸å¯¹è·¯å¾„ï¼ˆä»¥ ./ æˆ– ../ å¼€å¤´ï¼‰
    elif resource_path.startswith(('./', '../')):
        abs_path = os.path.abspath(os.path.join(current_note_dir, resource_path))

        # ç¡®ä¿è·¯å¾„åœ¨ä»“åº“æ ¹ç›®å½•å†…
        if not abs_path.startswith(os.path.abspath(source_dir)):
            logger.warning(f"èµ„æºè·¯å¾„è¶…å‡ºä»“åº“èŒƒå›´ï¼š{abs_path}")
            resource_cache[cache_key] = None
            return None

        possible_paths.append(abs_path)
        
    # å°è¯•è§£æå…¶ä»–ç›¸å¯¹è·¯å¾„
    else:
        # å°è¯•ç›¸å¯¹äºå½“å‰ä»“åº“çš„ç›¸å¯¹è·¯å¾„
        direct_path = os.path.normpath(os.path.join(source_dir, resource_path))
        possible_paths.append(direct_path)
        
        # å°è¯•ç›¸å¯¹äºå½“å‰ç¬”è®°çš„éšå¼ç›¸å¯¹è·¯å¾„
        abs_path = os.path.normpath(os.path.join(current_note_dir, resource_path))
        possible_paths.append(abs_path)
        
    for path in possible_paths:
        # åˆ¤æ–­è·¯å¾„æ˜¯å¦ä¸ºæ–‡ä»¶
        if os.path.isfile(path):
            rel_path = os.path.relpath(path, source_dir)
            resource_cache[cache_key] = rel_path
            return rel_path
        # æ–‡ä»¶åå½¢å¦‚ï¼šfile.ext.extï¼Œä½†æ’å…¥çš„å¯èƒ½æ˜¯ file.ext
        # å°è¯•ç›´æ¥æ·»åŠ æ‰©å±•å
        else:
            for ext in all_extensions:
                extended_path = f"{path}.{ext}"
                if os.path.isfile(extended_path):
                    rel_path = os.path.relpath(extended_path, source_dir)
                    resource_cache[cache_key] = rel_path
                    return rel_path

    # å°è¯•å…¨åº“æ–‡ä»¶åæœç´¢     
    filename = os.path.basename(resource_path)
    for root, _, files in os.walk(source_dir):
        for file in files:
            # åŒ¹é…æ–‡ä»¶åï¼ˆå¸¦æ‰©å±•åæˆ–ä¸å¸¦æ‰©å±•åï¼‰
            if file == filename or any(file == f"{filename}.{ext}" for ext in all_extensions):
                file_path = os.path.join(root, file)
                if os.path.isfile(file_path):
                    rel_path = os.path.relpath(file_path, source_dir)
                    resource_cache[cache_key] = rel_path
                    return rel_path

    # æœªæ‰¾åˆ°èµ„æº
    resource_cache[cache_key] = None
    return None


def is_web_link(link):
    """
    åˆ¤æ–­é“¾æ¥æ˜¯å¦ä¸ºç½‘é¡µé“¾æ¥
    """
    # 1. å¦‚æœä»¥http://æˆ–https://å¼€å¤´
    if link.startswith(('http://', 'https://')):
        return True
    
    # 2. å¸¸è§ç½‘ç»œåè®®
    if link.startswith(('ftp://', 'mailto:', 'tel:')):
        return True
    
    # 3. æ ‡å‡†URLæ ¼å¼ï¼ˆå¸¦åŸŸåï¼‰
    domain_pattern = re.compile(
        r'^(?:[a-zA-Z0-9-]+\.)+[a-zA-Z]{2,}'  # åŸŸå
        r'(?::\d+)?'  # ç«¯å£
        r'(?:/[^\s]*)?$'  # è·¯å¾„
    )
    if domain_pattern.match(link):
        return True
    
    # 4. åè®®ç›¸å¯¹URLï¼ˆè§†ä¸ºå¤–éƒ¨é“¾æ¥ï¼‰
    if link.startswith('//'):
        return True
    
    # 5. æœ¬åœ°ç½‘ç»œåœ°å€ï¼ˆè§†ä¸ºæœ¬åœ°é“¾æ¥ï¼‰
    if 'localhost' in link.lower() or '127.0.0.1' in link.lower():
        return False
    
    # 6. å…¶ä»–æƒ…å†µè§†ä¸ºæœ¬åœ°é“¾æ¥
    return False


def get_file_type(file_path):
    """æ ¹æ®æ–‡ä»¶æ‰©å±•åè·å–æ–‡ä»¶ç±»å‹"""
    ext = file_path.split('.')[-1].lower() if '.' in file_path else ''
    for file_type, extensions in supported_extensions.items():
        if ext in extensions:
            return file_type
    return 'other'


def encode_url_space_only(url):
    """
    ä»…å¯¹URLä¸­çš„ç©ºæ ¼è¿›è¡Œç¼–ç 
    """
    return url.replace(" ", "%20")

def decode_url_space_only(url):
    """
    ä»…å¯¹URLä¸­çš„ç©ºæ ¼è¿›è¡Œè§£ç 
    """
    return url.replace("%20", " ")


def convert_wiki_links(note_file_path, updated_content):
    """
    å°†æ–‡ä»¶ä¸­çš„ Obsidian Wiki é“¾æ¥è½¬æ¢ä¸º Markdown è¶…é“¾æ¥æ ¼å¼
    :param note_file_path: ç¬”è®°æ–‡ä»¶è·¯å¾„
    :param updated_content: ç¬”è®°å†…å®¹
    """
    # å½“å‰ç¬”è®°æ‰€åœ¨ç›®å½•
    current_note_dir = os.path.dirname(note_file_path)
    
    # éå†æ‰€æœ‰åŒ¹é…åˆ°çš„é“¾æ¥
    matches = extract_wiki_links(updated_content)
    
    # print("matches:", matches)
    # æŒ‰é“¾æ¥åœ¨æ–‡æ¡£ä¸­çš„ä½ç½®æ’åº
    matches.sort(key=lambda m: m['start'])
    
    parts = []  # ç”¨äºå­˜å‚¨å¤„ç†åçš„å†…å®¹ç‰‡æ®µ
    last_end = 0   # è®°å½•ä¸Šä¸€æ¬¡åŒ¹é…ç»“æŸçš„ä½ç½®
    
    if matches:
        for match in matches:
            parts.append(updated_content[last_end:match['start']])
            resource_path = match['path']
            
            if not resource_path:
                resource_path = note_file_path
                
            resource_name = os.path.basename(resource_path)
            resource_relpath = find_resource_file(target_note_dir, resource_path, current_note_dir)
            
            if resource_relpath:
                # è®¡ç®—ç›¸å¯¹ä»“åº“æ ¹ç›®å½•çš„è·¯å¾„
                rel_path = resource_relpath.replace('\\', '/')  # ç»Ÿä¸€ä½¿ç”¨æ­£æ–œæ 
                # print('rel_path:', rel_path)
                
                # è®¡ç®—å¤–éƒ¨é“¾æ¥
                full_url = f'{external_link_prefix}{rel_path}'
                
                # æ„å»ºæ–°çš„é“¾æ¥å†…å®¹
                if match['embed']:
                    full_path = f'!['
                else:
                    full_path = f'['
                if not match['desc'] and not match['size']:
                    full_path += f'{resource_name}'
                elif match['desc']:
                    full_path += f'{match["desc"]}'
                    if match['size']:
                        full_path += f'|{match["size"]}'
                else:
                    full_path += f'{match["size"]}'
                full_path += f']('

                if match['title'] and not match['block_id']:
                    full_url += f'#{match["title"]}'
                if (not match['title']) and match['block_id']:
                    full_url += f'#^{match["block_id"]}'
                full_url = decode_url_space_only(full_url)
                full_url = encode_url_space_only(full_url)
                full_path += full_url + ')'
            else:
                full_path = match['full_match']
                logger.warning(f"âš ï¸ è­¦å‘Š: èµ„æºæœªæ‰¾åˆ°ï¼š {resource_path}")
                logger.warning(f"ğŸ“ åœ¨ç¬”è®°ä¸­: {note_file_path}")
                logger.warning(f"â© æ­¤èµ„æºé“¾æ¥ï¼š{full_path}")
 
            # æ·»åŠ åŒ¹é…åˆ°çš„é“¾æ¥åˆ°å†…å®¹ç‰‡æ®µ
            parts.append(full_path)
            last_end = match['end']  # æ›´æ–°ä¸Šæ¬¡å¤„ç†ç»“æŸä½ç½®

        # æ·»åŠ æœ€åä¸€ä¸ªç‰‡æ®µ
        parts.append(updated_content[last_end:])

        # å°†æ‰€æœ‰ç‰‡æ®µé‡æ–°ç»„åˆæˆæ–°çš„å†…å®¹
        updated_content = ''.join(parts)

        return updated_content 

    return updated_content


def convert_markdown_links(note_file_path, updated_content):
    """
    å°† Markdown é“¾æ¥è½¬æ¢ä¸º Web å¯è®¿é—®çš„å¤–éƒ¨é“¾æ¥æ ¼å¼
    """
    # å½“å‰ç¬”è®°æ‰€åœ¨ç›®å½•
    current_note_dir = os.path.dirname(note_file_path)
    
    # æå–æ‰€æœ‰èµ„æºé“¾æ¥å’Œå›¾ç‰‡åŒ¹é…é¡¹
    matches = extract_markdown_links(updated_content)
    
    # æŒ‰èµ·å§‹ä½ç½®æ­£å‘æ’åº
    matches.sort(key=lambda m: m['start'])
    
    # ä½¿ç”¨åˆ—è¡¨æ‹¼æ¥æ„å»ºæ–°å†…å®¹
    parts = []
    last_end = 0  # è®°å½•ä¸Šæ¬¡å¤„ç†ç»“æŸä½ç½®
    
    if matches: 
        for match in matches:
            type = match['type']
            embed = match['embed']
            resource_path = match['path']
            title = match['title']
            block_id = match['block_id']
            desc = match['desc']
            size = match['size']
            if size:
                if 'x' in size:
                    width, height = size.split('x')[0], size.split('x')[1]
                else:
                    width, height = size, None
            else:
                width, height = None, None
            
            # æ·»åŠ åŒ¹é…å‰çš„æ–‡æœ¬
            parts.append(updated_content[last_end:match['start']])

            if not resource_path:
                resource_path = note_file_path

            # å¤„ç†æœ¬åœ°èµ„æºé“¾æ¥
            if not is_web_link(resource_path):
                resource_path = decode_url_space_only(resource_path)
                resource_name = os.path.basename(resource_path)
                
                # æŸ¥æ‰¾èµ„æºæ–‡ä»¶çš„ç›¸å¯¹è·¯å¾„
                resource_relpath = find_resource_file(target_note_dir, resource_path, current_note_dir)
                
                # å¦‚æœæ‰¾åˆ°èµ„æºï¼Œç”Ÿæˆå¤–éƒ¨é“¾æ¥æ ¼å¼
                if resource_relpath:
                    # è®¡ç®—ç›¸å¯¹ä»“åº“æ ¹ç›®å½•çš„è·¯å¾„
                    rel_path = resource_relpath.replace('\\', '/')  # ç»Ÿä¸€ä½¿ç”¨æ­£æ–œæ 
                    
                    # è®¡ç®—å¤–éƒ¨é“¾æ¥
                    full_url = f'{external_link_prefix}{rel_path}'
                    
                    if match['title'] and not match['block_id']:
                        full_url += f'#{match["title"]}'
                    # if (not match['title']) and match['block_id']:
                    #     full_url += f'#^{match["block_id"]}'
                    full_url = decode_url_space_only(full_url)
                    full_url = encode_url_space_only(full_url)
                        
                    file_type = get_file_type(resource_name)
                    
                    if file_type == 'image':
                        alt_text = desc or resource_name
                        alt_text = decode_url_space_only(alt_text)
                        if embed:
                            # ç”ŸæˆåµŒå…¥å¼å›¾ç‰‡çš„ HTML
                            if width and height:
                                full_path = f'<img src="{full_url}" width="{width}" height="{height}" alt="{alt_text}" />'
                            elif width:
                                full_path = f'<img src="{full_url}" width="{width}" alt="{alt_text}" />'
                            elif height:
                                full_path = f'<img src="{full_url}" height="{height}" alt="{alt_text}" />'
                            else:
                                full_path = f'<img src="{full_url}" alt="{alt_text}" />'
                        else:
                            # ç”Ÿæˆå›¾ç‰‡çš„ Markdown é“¾æ¥
                            if width and height:
                                full_path = f'[{alt_text}|{width}x{height}]({full_url})'
                            elif width:
                                full_path = f'[{alt_text}|{width}]({full_url})'
                            elif height:
                                full_path = f'[{alt_text}|{height}]({full_url})'
                            else:
                                full_path = f'[{alt_text}]({full_url})'     
                    else:
                        # ç”Ÿæˆå…¶ä»–æ–‡ä»¶çš„ Markdown é“¾æ¥
                        display_text = desc or title or block_id or resource_name
                        display_text = decode_url_space_only(display_text)
                        if embed:
                            full_path = f'![{display_text}]({full_url})'
                        full_path = f'[{display_text}]({full_url})'
                else:
                    full_path = match['full_match']
                    logger.warning(f"âš ï¸ è­¦å‘Š: èµ„æºæœªæ‰¾åˆ°ï¼š {resource_path}")
                    logger.warning(f"ğŸ“ åœ¨ç¬”è®°ä¸­: {note_file_path}")
                    logger.warning(f"â© ä¿ç•™åŸå§‹é“¾æ¥ï¼š{full_path}")
            
            else:
                full_path = match['full_match']
 
            # æ·»åŠ åŒ¹é…åˆ°çš„é“¾æ¥åˆ°å†…å®¹ç‰‡æ®µ
            parts.append(full_path)
            last_end = match['end']
            
        # æ·»åŠ æœ€åä¸€ä¸ªç‰‡æ®µ
        parts.append(updated_content[last_end:])
        
        # æ‹¼æ¥æ‰€æœ‰éƒ¨åˆ†
        updated_content = ''.join(parts)
    
    return updated_content


def update_resource_links(note_file_path):
    """
    æ›´æ–°æ–‡ä»¶ä¸­çš„èµ„æºé“¾æ¥ä¸ºå¤–éƒ¨è®¿é—®é“¾æ¥
    :param note_file_path: ç¬”è®°æ–‡ä»¶è·¯å¾„
    """
    with open(note_file_path, 'r', encoding='utf-8', newline='') as file:
        try:
            content = file.read()
            # print("content[:100]:", content[:100])  # æ‰“å°å‰100ä¸ªå­—ç¬¦ä½œä¸ºæµ‹è¯•
        except IOError as e:
            print(f"IOError: {e}")
        except UnicodeDecodeError as e:
            print(f"UnicodeDecodeError: {e}")
        except Exception as e:
            print(f"Unexpected error: {e}")

    # æå–ä»£ç å†…å®¹å¹¶ç”¨å ä½ç¬¦æ›¿æ¢
    updated_content, code_blocks = save_code_blocks(content)
    
    # è½¬æ¢ä¸º Markdown é“¾æ¥æ ¼å¼
    updated_content = convert_wiki_links(note_file_path, updated_content)
    
    # è½¬æ¢ä¸º Web å¯è®¿é—®çš„å¤–éƒ¨é“¾æ¥æ ¼å¼
    updated_content = convert_markdown_links(note_file_path, updated_content)
    
    # æ¢å¤ä»£ç å—
    updated_content = restore_code_blocks(updated_content, code_blocks)

    with open(note_file_path, 'w', encoding='utf-8', newline='') as file:
        try:
            file.write(updated_content)
            # print(f"âœ… æˆåŠŸæ›´æ–°æ–‡ä»¶: {note_file_path}")
        except Exception as e:
            logger.error(f"âš ï¸ å†™å…¥æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯:{e}")


def iterate_files(target_note_dir):
    """éå†ç›®æ ‡ç›®å½•ä¸­çš„æ‰€æœ‰ç¬”è®°æ–‡ä»¶æ›´æ–°é“¾æ¥"""
    ignored_dirs = get_ignore_list(target_note_dir)
    updated_count = 0
    for root, dirs, files in os.walk(target_note_dir):
        # æ’é™¤ç‰¹å®šå­ç›®å½•
        dirs[:] = [d for d in dirs if d not in ignored_dirs]

        for file in files:
            if file.endswith('.md'):
                note_file_path = os.path.join(root, file)
                updated_count += 1
                logger.info(f"å¤„ç†ç¬”è®°: {note_file_path}")
                update_resource_links(note_file_path)
                
    return updated_count


def main():
    """æ‰§è¡Œæ–‡ä»¶å¤åˆ¶å’Œæ›´æ–°æ“ä½œ"""
    # ç¡®è®¤åˆ é™¤ç›®æ ‡ç›®å½•
    safe_remove_if_exists(target_note_dir)
    # åˆ›å»ºæ–°ç›®å½•
    os.makedirs(target_note_dir, exist_ok=True)

    logger.info("å¼€å§‹å¤„ç†...")
    logger.info(f"æºç›®å½•: {source_note_dir}")
    logger.info(f"ç›®æ ‡ç›®å½•: {target_note_dir}")

    # å¤åˆ¶æ–‡ä»¶ï¼ˆå¿½ç•¥ç‰¹å®šæ‰©å±•åï¼‰
    ignored_extensions = ['.tmp', '.DS_Store']
    # copy_files(source_note_dir, ignored_extensions)
    copy_files_with_timestamps(source_note_dir, ignored_extensions)

    # æ›´æ–°ç¬”è®°ä¸­çš„èµ„æºé“¾æ¥
    updated_count = iterate_files(target_note_dir)

    logger.info("\nâœ… å¤„ç†å®Œæˆï¼")
    logger.info(f"å…±å¤„ç† {updated_count} ä¸ªç¬”è®°: {target_note_dir}")


if __name__ == "__main__":
    # è®¾ç½®æ—¥å¿—çº§åˆ«
    logger.setLevel(logging.INFO)
    main()
