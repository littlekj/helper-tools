"""
éœ€æ±‚ç›®æ ‡

å°† Markdown æ–‡ä»¶ä¸­å¼•ç”¨çš„æœ¬åœ°èµ„æºè·¯å¾„ï¼ˆå¦‚å›¾ç‰‡ã€æ–‡ä»¶ï¼‰è‡ªåŠ¨è½¬æ¢ä¸ºå¯é€šè¿‡ Web è®¿é—®çš„å¤–éƒ¨ URL æ ¼å¼ã€‚

å¤„ç† Obsidian æ–‡æ¡£ä¸­çš„é“¾æ¥æ ¼å¼èŒƒå›´ï¼š

1. Obsidian æ”¯æŒçš„ Wiki é“¾æ¥æ ¼å¼

- å½“å‰æ–‡ä»¶å†…é”šç‚¹é“¾æ¥ï¼š`[[#æ ‡é¢˜]]`     
- å½“å‰æ–‡ä»¶å†…å—æ ‡è¯†ç¬¦é“¾æ¥ï¼š`[[#^å—æ ‡è¯†ç¬¦]]`
- æ™®é€šæ–‡ä»¶é“¾æ¥ï¼š`[[assets/file1.md]]`
- æ”¯æŒæ–‡ä»¶å¸¦é”šç‚¹ï¼š`[[assets/file2.md#æ ‡é¢˜]]`
- æ”¯æŒæ–‡ä»¶å¸¦å—æ ‡è¯†ç¬¦ï¼š`[[assets/file3.md#^å—æ ‡è¯†ç¬¦]]`
- æ”¯æŒæ–‡ä»¶å¸¦åˆ«åï¼š`[[assets/file4.md|åˆ«å]]`
- æ”¯æŒæ–‡ä»¶å¸¦é”šç‚¹å’Œåˆ«åï¼š`[[assets/file5.md#æ ‡é¢˜|åˆ«å]]`
- æ”¯æŒæ–‡ä»¶å¸¦å—æ ‡è¯†ç¬¦å’Œåˆ«åï¼š`[[assets/file6.md#^å—æ ‡è¯†ç¬¦|åˆ«å]]`
- å›¾ç‰‡èµ„æºé“¾æ¥ï¼š`![[assets/image1.png]]`
- æ”¯æŒå›¾ç‰‡å¸¦å°ºå¯¸å£°æ˜ï¼š`![[assets/image2.png | 400x300]]`
- æ”¯æŒå›¾ç‰‡ä»…æŒ‡å®šå®½åº¦ï¼š`![[assets/image3.png | 400]]`

2. æ ‡å‡† Markdown é“¾æ¥æ ¼å¼

- å½“å‰æ–‡ä»¶å†…é”šç‚¹é“¾æ¥ï¼š`[åˆ«å](#æ ‡é¢˜)`
- æ™®é€šæ–‡ä»¶é“¾æ¥ï¼š`[åˆ«å](assets/file7.md)`
- æ”¯æŒæ–‡ä»¶å¸¦é”šç‚¹ï¼š`[åˆ«å](assets/file8.md#æ ‡é¢˜)`
- å›¾ç‰‡èµ„æºé“¾æ¥ï¼š`![æè¿°](assets/image4.png)`
- æ™®é€šèµ„æºé“¾æ¥æŒ‡å‘å›¾ç‰‡ï¼š`[æè¿°](assets/image5.png)`
   
3. Obsidian Markdown æ‰©å±•

- å½“å‰æ–‡ä»¶å†…é”šç‚¹åµŒå…¥ï¼š`![åˆ«å](#æ ‡é¢˜)`
- å½“å‰æ–‡ä»¶å†…å—æ ‡è¯†ç¬¦åµŒå…¥`![åˆ«å](#^å—æ ‡è¯†ç¬¦)`
- å½“å‰æ–‡ä»¶å†…å—æ ‡è¯†ç¬¦é“¾æ¥ï¼š`[åˆ«å](#^å—æ ‡è¯†ç¬¦)`
- æ”¯æŒæ–‡ä»¶å¸¦å—æ ‡è¯†ç¬¦ï¼š`[åˆ«å](assets/file9.md#^å—æ ‡è¯†ç¬¦)`
- æ”¯æŒå›¾ç‰‡å¸¦å°ºå¯¸å£°æ˜ï¼š`![400x300](assets/image6.png)`
- æ”¯æŒå›¾ç‰‡å¸¦æè¿°å’Œå°ºå¯¸å£°æ˜ï¼š`![æè¿° | 400x300](assets/image7.png)`
- æ”¯æŒå›¾ç‰‡å¸¦æè¿°å’Œä»…å®½åº¦å£°æ˜ï¼š`![æè¿° | 400](assets/image8.png)`

4. Obsidian ç‰¹æ®ŠåµŒå…¥æ ¼å¼

- å½“å‰æ–‡ä»¶å†…é”šç‚¹åµŒå…¥ï¼š`![[#æ ‡é¢˜]]`
- å½“å‰æ–‡ä»¶å†…å—æ ‡è¯†ç¬¦åµŒå…¥ï¼š`![[#^å—æ ‡è¯†ç¬¦]]`
- åµŒå…¥æ–‡ä»¶å†…å®¹ï¼š`![[assets/file10.md]]`
- åµŒå…¥ PDF é¡µé¢æŒ‡å®šé¡µæ•°ï¼š`![[assets/doc.pdf#page=3]]`

5. è¡¥å……ï¼š

- ![æè¿°](http://example.com/image.png)
- ![æè¿°](https://example.com/audio.mp3)
- ![æè¿°|400x300](assets/image%20copy.png)

å¤„ç†è¯´æ˜:

- å°†æ‰€æœ‰æœ¬åœ°èµ„æºè·¯å¾„è½¬æ¢ä¸ºå¤–éƒ¨ URL æ ¼å¼ï¼Œå¹¶ä¿ç•™åŸå§‹é“¾æ¥çš„åˆ«åå’Œæè¿°ã€‚
- åµŒå…¥å›¾ç‰‡é“¾æ¥ï¼Œç”ŸæˆåµŒå…¥å¼å›¾ç‰‡çš„ HTMLï¼Œå¯ä¿ç•™åŸå§‹é“¾æ¥çš„æè¿°å’Œå°ºå¯¸å£°æ˜ã€‚
- éåµŒå…¥å›¾ç‰‡é“¾æ¥ï¼Œç”Ÿæˆå›¾ç‰‡çš„ Markdown é“¾æ¥ï¼Œå¯ä¿ç•™åŸå§‹é“¾æ¥çš„æè¿°ã€‚
- æ™®é€šæ–‡ä»¶é“¾æ¥ï¼Œç”Ÿæˆæ–‡ä»¶çš„ Markdown é“¾æ¥ï¼Œå¯ä¿ç•™åŸå§‹é“¾æ¥çš„é”šç‚¹æ ‡é¢˜å’Œåˆ«åï¼Œä½†ä¸ä¿ç•™å—æ ‡è¯†ç¬¦ã€‚

"""
import os
import shutil
import re
from urllib.parse import quote
import sys
from pathlib import Path
import logging

import argparse
import subprocess
import shlex
from typing import Optional

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
logger = logging.getLogger('ObsidianLinkConverter')

# é…ç½®è·¯å¾„
source_folder = "Default"
source_note_dir = fr'D:\Obsidian\Default'
target_note_dir = fr'D:\Obsidian\Middle\obsidianlinks'
internal_link_prefix = r''  # å†…éƒ¨é“¾æ¥å‰ç¼€
# external_link_prefix = r''  # å¤–éƒ¨é“¾æ¥å‰ç¼€
# external_link_prefix = r'https://raw.githubusercontent.com/littlekj/linkres/master/obsidian/'
external_link_prefix = '/'  # ç›¸å¯¹åœ°å€å‰ç¼€æ·»åŠ  / ç”Ÿæˆç»å¯¹è·¯å¾„ï¼Œæ‹¼æ¥ GitHub ä»“åº“åœ°å€ä¾¿äº Web è®¿é—®


# Obsidian æ”¯æŒçš„æ–‡ä»¶æ ¼å¼
supported_extensions = {
    'markdown': ['md'],
    'image': ['png', 'jpg', 'jpeg', 'gif', 'bmp', 'avif', 'webp', 'svg'],
    'audio': ['flac', 'm4a', 'mp3', 'ogg', 'wav', 'webm', '3gp'],
    'video': ['mkv', 'mov', 'mp4', 'ogv', 'webm', 'avi'],
    'pdf': ['pdf']
}

# æ„å»ºæ‰€æœ‰æ‰©å±•åçš„æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼
all_extensions = []
for category in supported_extensions.values():
    all_extensions.extend(category)
    
# å…¨å±€èµ„æºç¼“å­˜ï¼ˆé¿å…é‡å¤æŸ¥æ‰¾ï¼‰
resource_cache = {}


# åªåœ¨ Windows å¹³å°å¯¼å…¥ pywin32 æ¨¡å—
if os.name == 'nt':
    try:
        import win32file
        import pywintypes
    except ImportError:
        print("è¯·å®‰è£… pywin32 åº“ä»¥ä¿®å¤ç›®å½•çš„æ—¶é—´æˆ³")  


def fix_directory_timestamps(src_dir: str, dst_dir: str):
    """
    ä¿®å¤ Windows ä¸‹ç›®æ ‡ç›®å½•æ—¶é—´æˆ³ï¼ˆåˆ›å»ºã€ä¿®æ”¹ã€è®¿é—®ï¼‰
    """
    if not os.path.exists(dst_dir):
        print(f"æ— æ³•ä¿®å¤æ—¶é—´æˆ³ï¼šç›®æ ‡ç›®å½•ä¸å­˜åœ¨ {dst_dir}")
        return

    try:
        src_stat = os.stat(src_dir)
        ctime = pywintypes.Time(src_stat.st_ctime)
        atime = pywintypes.Time(src_stat.st_atime)
        mtime = pywintypes.Time(src_stat.st_mtime)

        handle = win32file.CreateFile(
            dst_dir,
            win32file.GENERIC_WRITE,
            win32file.FILE_SHARE_READ | win32file.FILE_SHARE_WRITE,
            None,
            win32file.OPEN_EXISTING,
            win32file.FILE_FLAG_BACKUP_SEMANTICS,  # ç”¨äºæ“ä½œç›®å½•
            None
        )
        try:
            win32file.SetFileTime(handle, ctime, atime, mtime)
        finally:
            handle.close()
    except Exception as e:
        print(f"ä¿®å¤ç›®å½•æ—¶é—´æˆ³å¤±è´¥ {dst_dir}: {e}")


def is_target_directory(src: str, dst: str) -> bool:
    """
    åˆ¤æ–­ç›®æ ‡è·¯å¾„æ˜¯å¦æ˜¯ç›®å½•ï¼ˆè€ƒè™‘éšè—æ–‡ä»¶ç‰¹æ®Šæ€§ï¼‰
    """
    # å¦‚æœç›®æ ‡è·¯å¾„å·²å­˜åœ¨ï¼Œåˆ™åˆ¤æ–­æ˜¯å¦æ˜¯ç›®å½•
    if os.path.exists(dst):
        if os.path.isdir(dst):
            return True
        else: 
            raise FileExistsError(f"ç›®æ ‡è·¯å¾„å·²å­˜åœ¨ä¸”ä¸æ˜¯ç›®å½•: {dst}")
    
    # ä»¥è·¯å¾„åˆ†éš”ç¬¦ç»“å°¾ï¼Œåˆ™è®¤ä¸ºæ˜¯ç›®å½•
    if dst.endswith('/') or dst.endswith('\\'):
        return True
    
    # å¦‚æœæºæ˜¯éšè—æ–‡ä»¶ï¼Œä¸”ç›®æ ‡è·¯å¾„æ— æ‰©å±•åä½†ä»¥ . å¼€å¤´ï¼Œåˆ™è§†ä¸ºæ–‡ä»¶
    if src and os.path.isfile(src):
        src_name = os.path.basename(src)
        if src_name.startswith('.'):
            dst_name = os.path.basename(dst)
            if dst_name.startswith('.') and os.path.splitext(dst)[1] == '':
                return False
    
    # å¦‚æœæºæ˜¯ç›®å½•ï¼Œåˆ™è®¤ä¸ºç›®æ ‡è·¯å¾„æ˜¯ç›®å½•     
    elif src and os.path.isdir(src):
            return True
    
    # ä¸€èˆ¬æƒ…å†µï¼šå¦‚æœç›®æ ‡è·¯å¾„æ— æ‰©å±•åï¼Œåˆ™è®¤ä¸ºæ˜¯ç›®å½•
    return os.path.splitext(dst)[1] == ''
            
    
def robocopy_copy(src: str, dst: str) -> bool:
    """
    Windows ç³»ç»Ÿä¸‹ä½¿ç”¨ robocopy å¤åˆ¶æ–‡ä»¶æˆ–ç›®å½•ï¼Œä¿ç•™æ—¶é—´æˆ³ï¼ˆåˆ›å»ºã€ä¿®æ”¹ã€è®¿é—®ï¼‰
    :param src: æºæ–‡ä»¶æˆ–ç›®å½•è·¯å¾„
    :param dst: ç›®æ ‡è·¯å¾„ï¼ˆæ–‡ä»¶æˆ–ç›®å½•ï¼‰
    """
    if not os.path.exists(src):
        raise FileNotFoundError(f"æºè·¯å¾„ä¸å­˜åœ¨: {src}")

    is_file = os.path.isfile(src)
    src_name = os.path.basename(src)

    dst_is_directory = is_target_directory(src, dst)
    if dst_is_directory:
        # ç›®æ ‡æ˜¯ç›®å½•ï¼Œå¤åˆ¶åˆ°è¯¥ç›®å½•ä¸‹ï¼Œä½¿ç”¨åŸæ–‡ä»¶å
        parent_dst = dst.rstrip('/\\')
        final_dst = os.path.join(parent_dst, src_name)
    else:
        # ç›®æ ‡æ˜¯æ–‡ä»¶ï¼Œç›´æ¥ä½¿ç”¨ç›®æ ‡æ–‡ä»¶å
        parent_dst = os.path.dirname(dst) or '.'  # å‡å¦‚ data.txt çˆ¶ç›®å½•ä¸ºç©ºï¼Œä½¿ç”¨å½“å‰ç›®å½•
        final_dst = dst
    
    # ç¡®ä¿çˆ¶ç›®å½•å­˜åœ¨ 
    os.makedirs(parent_dst, exist_ok=True)
    
    if is_file:
        parent_src = os.path.dirname(src)
        file_list = [src_name]
    else:
        parent_src = src
        file_list = []


    # ä¼˜å…ˆä½¿ç”¨ shell=False + åˆ—è¡¨
    # æ„å»º robocopy å‘½ä»¤
    cmd = [
        "robocopy",
        parent_src,      # æŒ‡å®šæºç›®å½•
        parent_dst,      # æŒ‡å®šç›®æ ‡ç›®å½•ï¼ˆrobocopy åªæ”¯æŒç›®å½•ï¼‰
        *file_list,      # æŒ‡å®šæ–‡ä»¶ååˆ—è¡¨
        "/COPY:DAT",     # å¤åˆ¶æ•°æ®ã€å±æ€§ã€æ—¶é—´æˆ³
        "/DCOPY:T",      # å¤åˆ¶ç›®å½•æ—¶é—´æˆ³ï¼ˆåˆ›å»ºã€ä¿®æ”¹ã€è®¿é—®ï¼‰
        # "/E",            # åŒ…å«å­ç›®å½•ï¼ˆå«ç©ºç›®å½•ï¼‰
        "/R:0", "/W:0",  # ä¸é‡è¯•
        "/NFL", "/NDL",  # ä¸è¾“å‡ºæ–‡ä»¶å’Œç›®å½•
        "/NJH", "/NJS",  # æ— ä½œä¸šå¤´å’Œå°¾
        "/NC", "/NS",    # ä¸è¾“å‡ºæ–‡ä»¶å¤§å°ã€æ‘˜è¦
        "/IS",           # å¤åˆ¶ç›¸åŒæ–‡ä»¶ï¼ˆä¸è·³è¿‡ï¼‰
        "/IT"            # å¤åˆ¶ç›¸åŒæ–‡ä»¶çš„æ—¶é—´æˆ³ï¼ˆå³ä½¿æ•°æ®æ²¡å˜ï¼‰
    ]

    if not is_file:
        cmd.append("/E")  # åŒ…å«å­ç›®å½•ï¼ˆå«ç©ºç›®å½•ï¼‰

    try:
        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            timeout=300,    # 5åˆ†é’Ÿè¶…æ—¶
            shell=False     # é¿å… shell æ³¨å…¥
            # shell=True      # æ”¯æŒå†…å»ºå‘½ä»¤å’Œå˜é‡æ›¿æ¢
        )

        # robocopy è¿”å›ç ï¼š0~7 æˆåŠŸï¼Œ8+ å¤±è´¥
        # 0: æ— å¤åˆ¶ï¼ˆæ–‡ä»¶å·²æœ€æ–°ï¼‰
        # 1: æˆåŠŸå¤åˆ¶æ–‡ä»¶
        # 2: æœ‰é¢å¤–æ–‡ä»¶
        # 3: 1+2
        # 8+: ä¸¥é‡é”™è¯¯
        success = result.returncode < 8

        # è¾“å‡ºæ—¥å¿—
        if result.stdout.strip():
            print("=== robocopy è¾“å‡º ===\n" + result.stdout)
        if result.stderr.strip():
            print("=== robocopy é”™è¯¯ ===\n" + result.stderr)

        if success:
            # æ–‡ä»¶åœºæ™¯ï¼šrobocopy å®é™…å¤åˆ¶åˆ°äº† parent_dst/src_nameï¼Œéœ€é‡å‘½åä¸º final_dst
            if is_file:
                temp_copied = os.path.join(parent_dst, src_name)
                if os.path.exists(temp_copied) and temp_copied != final_dst:
                    os.replace(temp_copied, final_dst)
            # ä¿®å¤ç›®å½•æ—¶é—´æˆ³ï¼ˆå¯é€‰ï¼‰
            if os.path.isdir(dst) and os.path.isdir(src):
                fix_directory_timestamps(src, dst)
        else:
            print(f"å¤åˆ¶å¤±è´¥ï¼ˆè¿”å›ç : {result.returncode}")

        return success

    except subprocess.TimeoutExpired:
        print("robocopy æ‰§è¡Œè¶…æ—¶")
        return False
    except Exception as e:
        print(f"robocopy æ‰§è¡Œå¤±è´¥: {e}")
        return False


def remote_path_type(user_host: str, remote_path: str) -> Optional[str]:
    """
    æ£€æŸ¥è¿œç¨‹è·¯å¾„ç±»å‹
    :return: 'file', 'directory', 'link', 'not_exists', None(æ‰§è¡Œå¤±è´¥)
    """
    quoted = shlex.quote(remote_path)
    check_cmd = (
        f"if [ -d {quoted} ]; then echo 'directory'; "
        f"elif [ -f {quoted} ]; then echo 'file'; "
        f"elif [ -L {quoted} ]; then echo 'link'; "
        f"else echo 'not_exists'; fi"
    )
    cmd = ["ssh", user_host, check_cmd]
    try:
        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            timeout=10,
            encoding='utf-8',
            errors='replace'
        )
        out = result.stdout.strip()
        if out in ('file', 'directory', 'link', 'not_exists'):
            return out
        return None
    except Exception as e:
        print(f"SSH æ£€æŸ¥å¤±è´¥: {e}")
        return None


def ensure_remote_dir(user_host: str, remote_path: str) -> bool:
    """é€šè¿‡ SSH ç¡®ä¿è¿œç¨‹ç›®å½•å­˜åœ¨"""
    cmd = ["ssh", user_host, f"mkdir -p {shlex.quote(remote_path)}"]
    try:
        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            encoding='utf-8',
            errors='replace'
        )
        return result.returncode == 0
    except Exception as e:
        print(f"åˆ›å»ºè¿œç¨‹ç›®å½•å¤±è´¥: {e}")
        return False


def rsync_copy(src: str, dst: str) -> bool:
    """
    Unix ç³»ç»Ÿï¼Œä½¿ç”¨ rsync å¤åˆ¶ä¿ç•™ä¿®æ”¹ã€è®¿é—®æ—¶é—´æˆ³
    æ”¯æŒï¼šæœ¬åœ°åˆ°æœ¬åœ°ã€æœ¬åœ°åˆ°è¿œç¨‹çš„å¤åˆ¶
    :param src: æºæ–‡ä»¶æˆ–ç›®å½•è·¯å¾„
    :param dst: ç›®æ ‡è·¯å¾„ï¼ˆæ–‡ä»¶æˆ–ç›®å½•ï¼‰ï¼Œæ”¯æŒ user@host:/path
    """
    if not os.path.exists(src):
        raise FileNotFoundError(f"æºè·¯å¾„ä¸å­˜åœ¨: {src}")

    src_path = src.rstrip('/') + '/' if os.path.isdir(src) else src

    # æ£€æŸ¥æ˜¯å¦æ˜¯è¿œç¨‹è·¯å¾„
    # is_remote = '@' in dst and ':' in dst
    # ä½¿ç”¨æ­£åˆ™è§£æè¿œç¨‹è·¯å¾„ï¼ˆæ”¯æŒ IPv6ï¼‰
    remote_match = r'^((?P<user>[^@]+)@)?(?P<host>\[[^\]]+\]|[^:]+):(?P<path>/.*)$'
    match = re.match(remote_match, dst)
    is_remote = bool(match)

    if is_remote:
        user = match.group('user') or ''
        host = match.group('host')
        user_host = f"{user}@{host}" if user else host
        remote_path = match.group('path').rstrip('/')
        remote_type = remote_path_type(user_host, remote_path)

        if remote_type is None:
            raise RuntimeError(f"æ— æ³•ç¡®å®šè¿œç¨‹è·¯å¾„ç±»å‹ï¼š{dst}")

        if os.path.isdir(src):
            # å¦‚æœæºæ˜¯ç›®å½•ï¼Œåˆ™ç›®æ ‡è·¯å¾„è¦ç¡®ä¿æ˜¯ç›®å½•
            if remote_type in ("directory", "link"):
                final_dst = f"{user_host}:{remote_path}/"
            elif remote_type == 'not_exists':
                ensure_remote_dir(user_host, remote_path)
                final_dst = f"{user_host}:{remote_path}/"
            else:
                raise RuntimeError(f"æºæ˜¯ç›®å½•ï¼Œç›®æ ‡ä¸èƒ½æ˜¯æ–‡ä»¶: {dst}")
        else:  # æºæ˜¯æ–‡ä»¶
            bname = os.path.basename(src)
            if remote_type == 'not_exists':
                if dst.endswith('/') or os.path.splitext(remote_path)[1] == '':
                    # ç›®æ ‡æ˜¯ç›®å½•
                    target_dir = remote_path.rstrip('/')
                    ensure_remote_dir(user_host, target_dir)
                    final_dst = f"{user_host}:{target_dir}/{bname}"
                else:
                    parent_remote = os.path.dirname(remote_path)
                    if parent_remote.strip('/') != "":  # é¿å…æ ¹ç›®å½•
                        ensure_remote_dir(user_host, parent_remote)
                    final_dst = f"{user_host}:{remote_path}"
            elif remote_type == 'directory':
                final_dst = f"{user_host}:{remote_path}/{bname}"
            else:
                final_dst = f"{user_host}:{remote_path}"
    else:
        if os.path.isdir(src):
            # æºæ˜¯ç›®å½•ï¼Œç›®æ ‡è·¯å¾„è¦ç¡®ä¿æ˜¯ç›®å½•
            final_dst = dst.rstrip("/") + "/"
            os.makedirs(final_dst, exist_ok=True)
        else:
            # æºæ˜¯æ–‡ä»¶ï¼Œç›®æ ‡è·¯å¾„åˆ¤æ–­
            if dst.endswith('/') or os.path.splitext(dst)[1] == '':
                dst = dst.rstrip('/')
                final_dst = os.path.join(dst, os.path.basename(src))
            else:
                final_dst = dst
            os.makedirs(os.path.dirname(final_dst), exist_ok=True)

    # æ„å»º rsync å‘½ä»¤
    cmd = ["rsync", "-a", "--atimes", src_path, final_dst]
    try:
        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            encoding='utf-8',
            errors='replace',
            timeout=300
        )
        if result.returncode == 0:
            return True

        outerr = result.stderr.lower()

        if "permission denied" in outerr or "rsync error" in outerr:
            cmd_sudo = ["sudo"] + cmd
            try:
                result2 = subprocess.run(
                    cmd_sudo,
                    capture_output=True,
                    text=True,
                    encoding='utf-8',
                    errors='replace',
                    timeout=300
                )
                return result2.returncode == 0
            except Exception:
                pass
        print("rsync å¤±è´¥:", result.stderr.strip())
        return False

    except subprocess.TimeoutExpired:
        print("rsync æ‰§è¡Œè¶…æ—¶")
        return False
    except FileNotFoundError:
        print("æœªæ‰¾åˆ° rsyncï¼Œå›é€€åˆ° shutil.copy2")
        return fallback_copy(src, dst)
    except Exception as e:
        print(f"rsync å¤åˆ¶å¤±è´¥: {e}")
        return False


def fallback_copy(src: str, dst: str) -> bool:
    """å›é€€å¤åˆ¶æ–¹æ¡ˆï¼ˆä½¿ç”¨ shutil.copy2ï¼Œä¿ç•™åŸºæœ¬æ—¶é—´æˆ³ï¼‰"""
    try:
        if os.path.isdir(src):
            if os.path.exists(dst):
                shutil.rmtree(dst)
            shutil.copytree(src, dst, copy_function=shutil.copy2)
        else:
            os.makedirs(os.path.dirname(dst), exist_ok=True)
            shutil.copy2(src, dst)
        return True
    except Exception as e:
        print(f"å›é€€å¤åˆ¶å¤±è´¥: {e}")
        return False


def copy_with_timestamps(src: str, dst: str) -> bool:
    """ç»Ÿä¸€æ¥å£ï¼šå¤åˆ¶å¹¶ä¿ç•™æ—¶é—´æˆ³"""
    if os.name == 'nt':  # Windows 
        return robocopy_copy(src, dst)
    else:  # Unix/Linux/macOS
        return rsync_copy(src, dst)
    

def copy_files_with_timestamps(source_note_dir, ignored_extensions=None):
    """å¤åˆ¶æºç›®å½•ä¸­æ‰€æœ‰æ–‡ä»¶åˆ°ç›®æ ‡ï¼Œå¹¶ä¿ç•™åŸå§‹æ—¶é—´æˆ³"""
    # try:
    #     from copy_with_timestamps import copy_with_timestamps
    # except ImportError:
    #     logger.error("æ— æ³•å¯¼å…¥ copy_with_timestamps æ¨¡å—ï¼Œè¯·ç¡®ä¿æ¨¡å—å­˜åœ¨ã€‚")
    
    ignored_extensions = ignored_extensions or []
    for item in os.listdir(source_note_dir):
        source_path = os.path.join(source_note_dir, item)
        if item.startswith('.') and os.path.isfile(source_path):
            # éšè—æ–‡ä»¶å¤åˆ¶æ—¶ï¼Œä¸åœ¨å¤åˆ¶å‘½ä»¤çš„ç›®æ ‡è·¯å¾„ä¸­æŒ‡å®šæ–‡ä»¶
            destination_path = os.path.join(target_note_dir)
            # print("destination_path", destination_path)
        else:
          destination_path = os.path.join(target_note_dir, item)
        
        # è·³è¿‡å¿½ç•¥çš„æ–‡ä»¶ç±»å‹
        if any(source_path.endswith(ext) for ext in ignored_extensions):
            continue
        
        if os.path.isdir(source_path):
            copy_with_timestamps(source_path, destination_path)
            logger.info(f"å¤åˆ¶ç›®å½•ï¼š{source_path} -> {destination_path}")
        else:
            copy_with_timestamps(source_path, destination_path)
            logger.info(f"å¤åˆ¶æ–‡ä»¶ï¼š{source_path} -> {destination_path}")


# åŒ¹é…å†…è”ä»£ç  å’Œ å¤šè¡Œä»£ç å—ï¼ˆåå¼•å·/æ³¢æµªå·ï¼Œ3ä¸ªæˆ–ä»¥ä¸Šï¼‰
# æ”¹è¿›çš„æ­£åˆ™ï¼šä¸ºæ¯ç§æƒ…å†µè®¾ç½®æ•è·ç»„ï¼Œå¹¶ç¡®ä¿å†…å®¹è¢«æ•è·
CODE_PATTERN = re.compile(
    r'(`[^`]+?`)'                                  # group 1: å†…è”ä»£ç 
    r'|(~{3,})([a-zA-Z][\w-]*)?\s*\n'              # group 2: æ³¢æµªå·å¼€å§‹, group 3: è¯­è¨€
    r'([\s\S]*?)\n'                                # group 4: æ³¢æµªå·å†…å®¹
    r'(~{3,})(?=\n|$)'                             # group 5: æ³¢æµªå·ç»“æŸ
    r'|(`{3,})([a-zA-Z][\w-]*)?\s*\n'              # group 6: åå¼•å·å¼€å§‹, group 7: è¯­è¨€
    r'([\s\S]*?)\n'                                # group 8: åå¼•å·å†…å®¹
    r'(`{3,})(?=\n|$)',                            # group 9: åå¼•å·ç»“æŸ
    re.MULTILINE
)


def save_code_blocks(content):
    code_blocks = []
    placeholder_counter = 0

    def replace_func(match):
        nonlocal placeholder_counter
        placeholder_counter += 1
        placeholder = f"__CODE_BLOCK_{placeholder_counter}__"

        if match.group(1):  # å†…è”ä»£ç 
            code = match.group(1)
        elif match.group(2):  # æ³¢æµªå·ä»£ç å—
            start_delim = match.group(2)   # ~~~
            lang = match.group(3) or ""    # å¯é€‰è¯­è¨€
            body = match.group(4)
            end_delim = match.group(5)     # ~~~
            # ä¿ç•™è¯­è¨€æ ‡è¯†
            code = f"{start_delim}{lang}\n{body}\n{end_delim}"
        else:  # åå¼•å·ä»£ç å—
            start_delim = match.group(6)   # ```
            lang = match.group(7) or ""    # å¯é€‰è¯­è¨€
            body = match.group(8)
            end_delim = match.group(9)     # ```
            # ä¿ç•™è¯­è¨€æ ‡è¯†
            code = f"{start_delim}{lang}\n{body}\n{end_delim}"

        code_blocks.append((placeholder, code))
        return placeholder

    new_content = CODE_PATTERN.sub(replace_func, content)
    return new_content, code_blocks


def restore_code_blocks(content, code_blocks):
    """
    å°†å ä½ç¬¦æ›¿æ¢å›åŸå§‹ä»£ç å—
    """
    for placeholder, code in code_blocks:
        content = content.replace(placeholder, code)
    return content

    
# Wiki é“¾æ¥æ­£åˆ™ï¼ˆæ”¯æŒè·¯å¾„/æ ‡é¢˜/å—/å°ºå¯¸/åˆ«åï¼Œç«–çº¿å‰åå¯æœ‰ç©ºæ ¼ï¼‰
wiki_link_regex = r"""
    (!?)                           # 1: å¯é€‰ "!"ï¼ˆembedï¼‰
    \[\[
        (?:([^\]\|\n#^]+?)\s*)?    # 2: è·¯å¾„ï¼ˆå¯é€‰ï¼Œè‡ªåŠ¨å»æ‰å°¾ç©ºæ ¼ï¼‰
        (?:\#(?:
            (?!\^)([^\]\|\n#^]+)   # 3: æ ‡é¢˜ï¼ˆ#xxxï¼‰
          | \^([^\]\|\n#]+)        # 4: å—æ ‡è¯†ç¬¦ï¼ˆ#^xxxï¼‰
        ))?
        (?:\s*\|\s*(\d{1,4}(?:x\d{1,4})?))?   # 5: å°ºå¯¸ï¼ˆ400 æˆ– 400x300ï¼‰
        (?:\s*\|\s*([^\]\n|]+))?              # 6: åˆ«å
    \]\]
"""

# Markdown é“¾æ¥æ­£åˆ™ï¼ˆæ”¯æŒè·¯å¾„/æ ‡é¢˜/å—/å°ºå¯¸ï¼Œæè¿°å»æ‰å°¾ç©ºæ ¼ï¼‰
markdown_link_regex = r"""
    (!)?                           # 1: å¯é€‰ "!"ï¼ˆembedï¼‰
    \[
        ([^\]\|\n]*?)\s*           # 2: æè¿°/åˆ«åï¼ˆå»å°¾ç©ºæ ¼ï¼‰
        (?:\s*\|\s*
            (\d{1,4}(?:x\d{1,4})?) # 3: å°ºå¯¸ï¼ˆ400 æˆ– 400x300ï¼‰
        )?
    \]
    \(
        ([^()\n#^]+?)?             # 4: è·¯å¾„ï¼ˆå¯é€‰ï¼‰
        (?:\#(?:
            (?!\^)([^()\n#^]+)     # 5: æ ‡é¢˜ï¼ˆ#xxxï¼‰
          | \^([^()\n#]+)          # 6: å—æ ‡è¯†ç¬¦ï¼ˆ#^xxxï¼‰
        ))?
    \)
"""

wiki_link_pattern = re.compile(wiki_link_regex, re.VERBOSE)
markdown_link_pattern = re.compile(markdown_link_regex, re.VERBOSE)


# def is_image(path: str) -> bool:
#     """åˆ¤æ–­æ˜¯å¦ä¸ºå›¾ç‰‡é“¾æ¥"""
#     extensions_with_dot = tuple(f'.{ext}' for ext in IMAGE_EXT)
#     return path.lower().endswith(extensions_with_dot)


def parse_desc_size(raw_desc_or_size, size_group):
    """è§£æå›¾ç‰‡æè¿°å’Œå°ºå¯¸"""
    if not size_group:
        if raw_desc_or_size and re.match(r'^\d{1,4}(?:x\d{1,4})?$', raw_desc_or_size):
            return None, raw_desc_or_size
        return raw_desc_or_size, None

    return raw_desc_or_size, size_group


def extract_wiki_links(text):
    """Obsidian Wiki é“¾æ¥è§£æ"""
    matches = []
    for match in wiki_link_pattern.finditer(text):
        # isImage = is_image(match.group(2))
        # if isImage:
        #     print("image_path:", match.group(2))
        full_match = match.group(0)
        # print("full_match:", full_match)
        embed = bool(match.group(1))
        path = match.group(2)
        title = match.group(3)
        block_id = match.group(4)
        desc = match.group(6)
        size = match.group(5)
        if desc and size:
                desc = 'a' + desc + 'b'
                size = 'c' + size + 'd'
                
        matches.append({
            'full_match': full_match,
            'type': 'wiki',
            'embed': embed,
            'path': path,
            'title': title,
            'block_id': block_id,
            'desc': desc,
            'size': size,
            'start': match.start(),
            'end': match.end(),
        })

    return matches


def extract_markdown_links(text):
    """Obsidian Markdown é“¾æ¥è§£æ"""
    matches = []
    for match in markdown_link_pattern.finditer(text):
        # print("match.groups():", match.groups())
        full_match = match.group(0)
        embed = bool(match.group(1))
        raw_desc_or_size = match.group(2)
        size_group = match.group(3)
        path = match.group(4)
        desc, size = parse_desc_size(raw_desc_or_size, size_group)
        title = match.group(5)
        block_id = match.group(6)
        
        matches.append({
            'full_match': full_match,
            'type': 'markdown',
            'embed': embed,
            'path': path,
            'title': title,
            'block_id': block_id,
            'desc': desc,
            'size': size,
            'start': match.start(),
            'end': match.end(),
        })

    return matches


def confirm_delete(path):
    """ç¡®è®¤æ˜¯å¦åˆ é™¤æŒ‡å®šè·¯å¾„"""
    confirm = input(f"âš ï¸  ç¡®è®¤åˆ é™¤å†…å®¹ï¼š{path}ï¼Ÿ(y/N): ").strip().lower()
    return confirm == 'y'    

def remove_if_exists(path):
    """åˆ é™¤æ–‡ä»¶æˆ–ç›®å½•ï¼Œå¦‚æœå­˜åœ¨"""
    if os.path.exists(path):
        if os.path.isfile(path):
            os.remove(path)
        elif os.path.isdir(path):
            shutil.rmtree(path)
        logger.info(f"å·²åˆ é™¤: {path}")

def safe_remove_if_exists(path):
    """å®‰å…¨åˆ é™¤ç›®å½•ï¼Œå…ˆç¡®è®¤å†æ‰§è¡Œ"""
    if confirm_delete(path):
        remove_if_exists(path)
    else:
        print("âŒ å·²å–æ¶ˆåˆ é™¤æ“ä½œã€‚") 
        sys.exit(1)  # ç«‹å³é€€å‡ºç¨‹åº


def copy_files(source_note_dir, ignored_extensions=None):
    """å¤åˆ¶æºç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶åˆ°ç›®æ ‡ç›®å½•"""
    ignored_extensions = ignored_extensions or []
    for item in os.listdir(source_note_dir):
        source_path = os.path.join(source_note_dir, item)
        destination_path = os.path.join(target_note_dir, item)

        # è·³è¿‡å¿½ç•¥çš„æ–‡ä»¶ç±»å‹
        if any(source_path.endswith(ext) for ext in ignored_extensions):
            continue

        # # è·³è¿‡ç‰¹å®šç³»ç»Ÿæ–‡ä»¶
        # if item.startswith('.') or item in ['Thumbs.db', 'desktop.ini']:
        #     continue

        if os.path.isdir(source_path):
            shutil.copytree(source_path, destination_path, dirs_exist_ok=True)
            logger.info(f"å¤åˆ¶ç›®å½•: {source_path} -> {destination_path}")
        else:
            shutil.copy2(source_path, destination_path)
            logger.info(f"å¤åˆ¶æ–‡ä»¶: {source_path} -> {destination_path}")


def get_ignore_list(target_dir):
    """è·å–å¿½ç•¥æ–‡ä»¶åˆ—è¡¨"""
    ignore_files_path = os.path.join(target_dir, '.gitignore')
    if not os.path.exists(ignore_files_path):
        return []

    ignored = []
    with open(ignore_files_path, 'r', encoding='utf-8', newline='') as f:
        for line in f:
            stripped_line = line.strip()
            if stripped_line and not stripped_line.startswith('#'):
                # å¤„ç†ç›®å½•å¿½ç•¥ï¼ˆç§»é™¤ç»“å°¾çš„/ï¼‰
                if stripped_line.endswith('/'):
                    stripped_line = stripped_line[:-1]
                ignored.append(stripped_line)
    return ignored


def find_resource_file(source_dir, resource_path, current_note_dir):
    """
    åœ¨ä»“åº“ä¸­æŸ¥æ‰¾èµ„æºæ–‡ä»¶
    :param source_dir: ä»“åº“æ ¹ç›®å½•
    :param resource_path: èµ„æºè·¯å¾„ï¼ˆå¯èƒ½åŒ…å«ç›¸å¯¹è·¯å¾„ï¼‰
    :param current_note_dir: å½“å‰ç¬”è®°æ‰€åœ¨ç›®å½•
    :return: åŸºäºä»“åº“æ ¹ç›®å½•çš„ç›¸å¯¹è·¯å¾„ï¼Œå¦‚æœæ‰¾ä¸åˆ°è¿”å›None
    """
    # è½¬æ¢URLç¼–ç çš„ç©ºæ ¼ä¸ºæ™®é€šç©ºæ ¼
    resource_path = decode_url_space_only(resource_path)

    # æ£€æŸ¥ç¼“å­˜
    cache_key = (resource_path, current_note_dir)
    if cache_key in resource_cache:
        return resource_cache[cache_key]

    # å°è¯•å¯èƒ½çš„è·¯å¾„ç»„åˆ
    possible_paths = []

    # ç›¸å¯¹äºå½“å‰ç¬”è®°çš„è·¯å¾„
    relative_to_note = os.path.join(current_note_dir, resource_path)
    possible_paths.append(relative_to_note)
    
    # ç›¸å¯¹äºä»“åº“æ ¹ç›®å½•çš„è·¯å¾„
    relative_to_root = os.path.join(source_dir, resource_path)
    possible_paths.append(relative_to_root)
    
    # å°è¯•è§£æç»å¯¹è·¯å¾„ï¼ˆä»¥ / å¼€å¤´ï¼‰
    if resource_path.startswith('/'):
        abs_path = os.path.abspath(os.path.join(source_dir, resource_path[1:]))
        possible_paths.append(abs_path)
        
    # å°è¯•è§£æç›¸å¯¹è·¯å¾„ï¼ˆä»¥ ./ æˆ– ../ å¼€å¤´ï¼‰
    elif resource_path.startswith(('./', '../')):
        abs_path = os.path.abspath(os.path.join(current_note_dir, resource_path))

        # ç¡®ä¿è·¯å¾„åœ¨ä»“åº“æ ¹ç›®å½•å†…
        if not abs_path.startswith(os.path.abspath(source_dir)):
            logger.warning(f"èµ„æºè·¯å¾„è¶…å‡ºä»“åº“èŒƒå›´ï¼š{abs_path}")
            resource_cache[cache_key] = None
            return None

        possible_paths.append(abs_path)
        
    # å°è¯•è§£æå…¶ä»–ç›¸å¯¹è·¯å¾„
    else:
        # å°è¯•ç›¸å¯¹äºå½“å‰ä»“åº“çš„ç›¸å¯¹è·¯å¾„
        direct_path = os.path.normpath(os.path.join(source_dir, resource_path))
        possible_paths.append(direct_path)
        
        # å°è¯•ç›¸å¯¹äºå½“å‰ç¬”è®°çš„éšå¼ç›¸å¯¹è·¯å¾„
        abs_path = os.path.normpath(os.path.join(current_note_dir, resource_path))
        possible_paths.append(abs_path)
        
    for path in possible_paths:
        # åˆ¤æ–­è·¯å¾„æ˜¯å¦ä¸ºæ–‡ä»¶
        if os.path.isfile(path):
            rel_path = os.path.relpath(path, source_dir)
            resource_cache[cache_key] = rel_path
            return rel_path
        # æ–‡ä»¶åå½¢å¦‚ï¼šfile.ext.extï¼Œä½†æ’å…¥çš„å¯èƒ½æ˜¯ file.ext
        # å°è¯•ç›´æ¥æ·»åŠ æ‰©å±•å
        else:
            for ext in all_extensions:
                extended_path = f"{path}.{ext}"
                if os.path.isfile(extended_path):
                    rel_path = os.path.relpath(extended_path, source_dir)
                    resource_cache[cache_key] = rel_path
                    return rel_path

    # å°è¯•å…¨åº“æ–‡ä»¶åæœç´¢     
    filename = os.path.basename(resource_path)
    for root, _, files in os.walk(source_dir):
        for file in files:
            # åŒ¹é…æ–‡ä»¶åï¼ˆå¸¦æ‰©å±•åæˆ–ä¸å¸¦æ‰©å±•åï¼‰
            if file == filename or any(file == f"{filename}.{ext}" for ext in all_extensions):
                file_path = os.path.join(root, file)
                if os.path.isfile(file_path):
                    rel_path = os.path.relpath(file_path, source_dir)
                    resource_cache[cache_key] = rel_path
                    return rel_path

    # æœªæ‰¾åˆ°èµ„æº
    resource_cache[cache_key] = None
    return None


# å¸¸è§é¡¶çº§åŸŸåï¼ˆTLDï¼‰ï¼Œç”¨äºåŒºåˆ† Web é“¾æ¥å’Œæœ¬åœ°æ–‡ä»¶
COMMON_TLDS = {
    # é€šç”¨
    'com', 'org', 'net', 'edu', 'gov', 'mil', 'int', 'biz', 'info', 'name', 'pro',
    'museum', 'coop', 'aero', 'post', 'geo', 'kid', 'law', 'mail', 'sco', 'web',
    # å›½å®¶
    'cn', 'uk', 'de', 'fr', 'jp', 'au', 'ca', 'ru', 'in', 'br', 'it', 'es', 'nl',
    # æ–°é€šç”¨
    'app', 'dev', 'io', 'ai', 'co', 'tv', 'xyz', 'online', 'site', 'store', 'tech',
    'cloud', 'space', 'blog', 'news', 'wiki', 'shop', 'bank', 'sport', 'game',
    'music', 'movie', 'photo', 'art', 'design', 'studio', 'today', 'world',
    # å…¶ä»–å¸¸è§
    'us', 'uk', 'eu', 'me', 'tv', 'cc', 'la', 'pw', 'info', 'mobi',
}

# æ–‡ä»¶æ‰©å±•åé»‘åå•ï¼ˆæ˜ç¡®ä¸æ˜¯ TLD çš„ï¼‰
FILE_EXTS = {
    'pdf', 'doc', 'docx', 'xls', 'xlsx', 'ppt', 'pptx',
    'txt', 'md', 'markdown', 'rtf', 'log',
    'jpg', 'jpeg', 'png', 'gif', 'bmp', 'svg', 'webp',
    'zip', 'rar', '7z', 'tar', 'gz', 'iso',
    'exe', 'dll', 'bin', 'apk', 'pkg',
    'mp3', 'wav', 'flac', 'mp4', 'avi', 'mkv', 'mov',
    'css', 'js', 'json', 'xml', 'html', 'htm',
    'py', 'java', 'cpp', 'c', 'h', 'go', 'rs', 'ts', 'sh',
    'tmp', 'bak', 'old', 'swp', 'lock',
}

def is_web_link(link: str) -> bool:
    """
    åˆ¤æ–­é“¾æ¥æ˜¯å¦ä¸ºç½‘é¡µé“¾æ¥ï¼ˆå¤–éƒ¨ç½‘ç»œèµ„æºï¼‰
    
    ç­–ç•¥ï¼š
    1. å…ˆæ’é™¤æ˜ç¡®çš„æœ¬åœ°é“¾æ¥
    2. å†åˆ¤æ–­æ˜ç¡®çš„ Web é“¾æ¥
    3. æœ€åç”¨ TLD + æ ¼å¼åˆ¤æ–­æ¨¡ç³Šæƒ…å†µ
    """
    if not isinstance(link, str) or not link.strip():
        return False
    link = link.strip()
    if not link:
        return False

    # 1. æ˜ç¡®çš„æœ¬åœ°æˆ–ç‰¹æ®Šåè®®é“¾æ¥ â†’ é Web
    private_ipprivate_ip_pattern = re.compile(
        r'\b127\.0\.0\.1\b'                    # å›ç¯åœ°å€
        r'|\b192\.168\.\d+\.\d+\b'             # 192.168.x.x
        r'|\b10\.\d+\.\d+\.\d+\b'              # 10.x.x.x
        r'|\b172\.(1[6-9]|2[0-9]|3[01])\.\d+\.\d+\b'  # 172.16.0.0 ~ 172.31.255.255
    )
    if (
        link.startswith('obsidian://') or
        link.startswith('file://') or
        'localhost' in link.lower() or
        private_ipprivate_ip_pattern.search(link)
    ):
        return False

    # 2. åè®®å¤´æ˜ç¡®çš„ Web é“¾æ¥
    if link.startswith(('http://', 'https://', 'ftp://', 'mailto:', 'tel:')):
        return True

    # 3. åè®®ç›¸å¯¹é“¾æ¥ï¼ˆ//example.comï¼‰
    if link.startswith('//'):
        return True

    # 4. ç›¸å¯¹è·¯å¾„æˆ–ç»å¯¹è·¯å¾„ â†’ æœ¬åœ°è·¯å¾„é“¾æ¥
    if link.startswith(('./', '../', '/')) or '\\' in link or link.startswith('\\\\'):
        return False
    
    # 5. çº¯æ–‡ä»¶ååˆ¤æ–­ï¼ˆä¼˜å…ˆäºåŸŸååˆ¤æ–­ï¼‰
    # å¦‚æœæ˜¯ xxx.yyy æ ¼å¼ï¼Œä¸” yyy ä¸æ˜¯å¸¸è§ TLDï¼Œåˆ™è§†ä¸ºæ–‡ä»¶
    filename_match = re.match(r'^[a-zA-Z0-9][a-zA-Z0-9._-]*\.([a-zA-Z0-9]{2,6})$', link)
    if filename_match:
        ext = filename_match.group(1).lower()
        # å¦‚æœæ‰©å±•ååœ¨æ–‡ä»¶é»‘åå•ä¸­ â†’ æœ¬åœ°
        if ext in FILE_EXTS:
            return False
        # å¦‚æœæ‰©å±•åæ˜¯å…¬è®¤ TLD â†’ Web
        if ext in COMMON_TLDS:
            return True
        # æ¨¡ç³Šæƒ…å†µï¼šä¸åœ¨ TLD åˆ—è¡¨ä¸­ â†’ å€¾å‘äºæœ¬åœ°ï¼ˆä¿å®ˆç­–ç•¥ï¼‰
        return False

    # 6. ä¸¥æ ¼åŸŸåæ ¼å¼ + TLD æ£€æŸ¥
    # ä¿®æ”¹æ­£åˆ™ï¼šæ˜ç¡®æ•è· TLD
    domain_pattern = re.compile(
        r'^'
        r'(?:[a-zA-Z0-9]([a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?\.)*'  # å­åŸŸï¼ˆå¯é€‰ï¼‰
        r'[a-zA-Z0-9]([a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?'         # ä¸»åŸŸåï¼ˆå¦‚ exampleï¼‰
        r'\.'                                                  # å¿…é¡»æœ‰ä¸€ä¸ªç‚¹
        r'[a-zA-Z]([a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?'            # é¡¶çº§åŸŸï¼ˆå¦‚ com, org, xn--ï¼‰
        r'(?::\d{1,5})?'                                       # å¯é€‰ç«¯å£ï¼ˆ:8080ï¼‰
        r'(?:/[^\s]*)?'                                        # å¯é€‰è·¯å¾„ï¼ˆ/path/to/pageï¼‰
        r'$', re.IGNORECASE
    )
    if domain_pattern.match(link):
        tld = link.split('.')[-1].lower()
        if tld in COMMON_TLDS:
            return True

    # 7. å…¶ä»–æƒ…å†µè§†ä¸ºæœ¬åœ°é“¾æ¥
    return False


def get_file_type(file_path):
    """æ ¹æ®æ–‡ä»¶æ‰©å±•åè·å–æ–‡ä»¶ç±»å‹"""
    ext = file_path.split('.')[-1].lower() if '.' in file_path else ''
    for file_type, extensions in supported_extensions.items():
        if ext in extensions:
            return file_type
    return 'other'


def encode_url_space_only(url):
    """
    ä»…å¯¹URLä¸­çš„ç©ºæ ¼è¿›è¡Œç¼–ç 
    """
    return url.replace(" ", "%20")

def decode_url_space_only(url):
    """
    ä»…å¯¹URLä¸­çš„ç©ºæ ¼è¿›è¡Œè§£ç 
    """
    return url.replace("%20", " ")


def convert_wiki_links(note_file_path, updated_content):
    """
    å°†æ–‡ä»¶ä¸­çš„ Obsidian Wiki é“¾æ¥è½¬æ¢ä¸º Markdown è¶…é“¾æ¥æ ¼å¼
    :param note_file_path: ç¬”è®°æ–‡ä»¶è·¯å¾„
    :param updated_content: ç¬”è®°å†…å®¹
    """
    # å½“å‰ç¬”è®°æ‰€åœ¨ç›®å½•
    current_note_dir = os.path.dirname(note_file_path)
    
    # éå†æ‰€æœ‰åŒ¹é…åˆ°çš„é“¾æ¥
    matches = extract_wiki_links(updated_content)
    
    # print("matches:", matches)
    # æŒ‰é“¾æ¥åœ¨æ–‡æ¡£ä¸­çš„ä½ç½®æ’åº
    matches.sort(key=lambda m: m['start'])
    
    parts = []  # ç”¨äºå­˜å‚¨å¤„ç†åçš„å†…å®¹ç‰‡æ®µ
    last_end = 0   # è®°å½•ä¸Šä¸€æ¬¡åŒ¹é…ç»“æŸçš„ä½ç½®
    
    if matches:
        for match in matches:
            parts.append(updated_content[last_end:match['start']])
            resource_path = match['path']
            
            if not resource_path:
                resource_path = note_file_path
                
            resource_name = os.path.basename(resource_path)
            resource_relpath = find_resource_file(target_note_dir, resource_path, current_note_dir)
            
            if resource_relpath:
                # è®¡ç®—ç›¸å¯¹ä»“åº“æ ¹ç›®å½•çš„è·¯å¾„
                rel_path = resource_relpath.replace('\\', '/')  # ç»Ÿä¸€ä½¿ç”¨æ­£æ–œæ 
                # print('rel_path:', rel_path)
                
                # æ‹¼æ¥æˆå®Œæ•´çš„ URL
                full_url = f'{internal_link_prefix}{rel_path}'
                
                # æ„å»ºæ–°çš„é“¾æ¥å†…å®¹
                if match['embed']:
                    full_path = f'!['
                else:
                    full_path = f'['
                if not match['desc'] and not match['size']:
                    full_path += f'{resource_name}'
                elif match['desc']:
                    full_path += f'{match["desc"]}'
                    if match['size']:
                        full_path += f'|{match["size"]}'
                else:
                    full_path += f'{match["size"]}'
                full_path += f']('

                if match['title'] and not match['block_id']:
                    full_url += f'#{match["title"]}'
                if (not match['title']) and match['block_id']:
                    full_url += f'#^{match["block_id"]}'
                full_url = decode_url_space_only(full_url)
                full_url = encode_url_space_only(full_url)
                full_path += full_url + ')'
            else:
                full_path = match['full_match']
                logger.warning(f"âš ï¸ è­¦å‘Š: èµ„æºæœªæ‰¾åˆ°ï¼š {resource_path}")
                logger.warning(f"ğŸ“ åœ¨ç¬”è®°ä¸­: {note_file_path}")
                logger.warning(f"â© æ­¤èµ„æºé“¾æ¥ï¼š{full_path}")
 
            # æ·»åŠ åŒ¹é…åˆ°çš„é“¾æ¥åˆ°å†…å®¹ç‰‡æ®µ
            parts.append(full_path)
            last_end = match['end']  # æ›´æ–°ä¸Šæ¬¡å¤„ç†ç»“æŸä½ç½®

        # æ·»åŠ æœ€åä¸€ä¸ªç‰‡æ®µ
        parts.append(updated_content[last_end:])

        # å°†æ‰€æœ‰ç‰‡æ®µé‡æ–°ç»„åˆæˆæ–°çš„å†…å®¹
        updated_content = ''.join(parts)

        return updated_content 

    return updated_content


def convert_markdown_links(note_file_path, updated_content):
    """
    å°† Markdown é“¾æ¥è½¬æ¢ä¸º Web å¯è®¿é—®çš„å¤–éƒ¨é“¾æ¥æ ¼å¼
    """
    # å½“å‰ç¬”è®°æ‰€åœ¨ç›®å½•
    current_note_dir = os.path.dirname(note_file_path)
    
    # æå–æ‰€æœ‰èµ„æºé“¾æ¥å’Œå›¾ç‰‡åŒ¹é…é¡¹
    matches = extract_markdown_links(updated_content)
    
    # æŒ‰èµ·å§‹ä½ç½®æ­£å‘æ’åº
    matches.sort(key=lambda m: m['start'])
    
    # ä½¿ç”¨åˆ—è¡¨æ‹¼æ¥æ„å»ºæ–°å†…å®¹
    parts = []
    last_end = 0  # è®°å½•ä¸Šæ¬¡å¤„ç†ç»“æŸä½ç½®
    
    if matches: 
        for match in matches:
            embed = match['embed']
            resource_path = match['path']
            title = match['title']
            block_id = match['block_id']
            desc = match['desc']
            size = match['size']
            if size:
                if 'x' in size:
                    width, height = size.split('x')[0], size.split('x')[1]
                else:
                    width, height = size, None
            else:
                width, height = None, None
            
            # æ·»åŠ åŒ¹é…å‰çš„æ–‡æœ¬
            parts.append(updated_content[last_end:match['start']])

            if not resource_path:
                resource_path = note_file_path

            # å¤„ç†æœ¬åœ°èµ„æºé“¾æ¥
            if not is_web_link(resource_path) and (not resource_path.startswith('obsidian://')):
                resource_path = decode_url_space_only(resource_path)
                resource_name = os.path.basename(resource_path)
                
                # æŸ¥æ‰¾èµ„æºæ–‡ä»¶çš„ç›¸å¯¹è·¯å¾„
                resource_relpath = find_resource_file(target_note_dir, resource_path, current_note_dir)
                
                # å¦‚æœæ‰¾åˆ°èµ„æºï¼Œç”Ÿæˆå¤–éƒ¨é“¾æ¥æ ¼å¼
                if resource_relpath:
                    # è®¡ç®—ç›¸å¯¹ä»“åº“æ ¹ç›®å½•çš„è·¯å¾„
                    rel_path = resource_relpath.replace('\\', '/')  # ç»Ÿä¸€ä½¿ç”¨æ­£æ–œæ 
                    
                    # æ‹¼æ¥æˆå®Œæ•´çš„ URL
                    external_link_prefix = r'/'
                    full_url = f'{external_link_prefix}{rel_path}'
                    
                    if match['embed']:
                        full_path = f'!['
                    else:
                        full_path = f'['
                    if not match['desc'] and not match['size']:
                        full_path += f'{resource_name}'
                    elif match['desc']:
                        full_path += f'{match["desc"]}'
                        if match['size']:
                            full_path += f'|{match["size"]}'
                    else:
                        full_path += f'{match["size"]}'
                    full_path += f']('
                    
                    if match['title'] and not match['block_id']:
                        full_url += f'#{match["title"]}'
                    # if (not match['title']) and match['block_id']:
                    #     full_url += f'#^{match["block_id"]}'
                    full_url = decode_url_space_only(full_url)
                    full_url = encode_url_space_only(full_url)
                    full_path += full_url + ')'    
                        
                else:
                    full_path = match['full_match']
                    logger.warning(f"âš ï¸ è­¦å‘Š: èµ„æºæœªæ‰¾åˆ°ï¼š {resource_path}")
                    logger.warning(f"ğŸ“ åœ¨ç¬”è®°ä¸­: {note_file_path}")
                    logger.warning(f"â© ä¿ç•™åŸå§‹é“¾æ¥ï¼š{full_path}")
            
            else:
                full_path = match['full_match']
 
            # æ·»åŠ åŒ¹é…åˆ°çš„é“¾æ¥åˆ°å†…å®¹ç‰‡æ®µ
            parts.append(full_path)
            last_end = match['end']
            
        # æ·»åŠ æœ€åä¸€ä¸ªç‰‡æ®µ
        parts.append(updated_content[last_end:])
        
        # æ‹¼æ¥æ‰€æœ‰éƒ¨åˆ†
        updated_content = ''.join(parts)
    
    return updated_content


def convert_markdown_links_blog(note_file_path, updated_content):
    """
    å°† Markdown é“¾æ¥è½¬æ¢ä¸º Web å¯è®¿é—®çš„å¤–éƒ¨é“¾æ¥æ ¼å¼
    """
    # å½“å‰ç¬”è®°æ‰€åœ¨ç›®å½•
    current_note_dir = os.path.dirname(note_file_path)
    
    # æå–æ‰€æœ‰èµ„æºé“¾æ¥å’Œå›¾ç‰‡åŒ¹é…é¡¹
    matches = extract_markdown_links(updated_content)
    
    # æŒ‰èµ·å§‹ä½ç½®æ­£å‘æ’åº
    matches.sort(key=lambda m: m['start'])
    
    # ä½¿ç”¨åˆ—è¡¨æ‹¼æ¥æ„å»ºæ–°å†…å®¹
    parts = []
    last_end = 0  # è®°å½•ä¸Šæ¬¡å¤„ç†ç»“æŸä½ç½®
    
    if matches: 
        for match in matches:
            embed = match['embed']
            resource_path = match['path']
            title = match['title']
            block_id = match['block_id']
            desc = match['desc']
            size = match['size']
            if size:
                if 'x' in size:
                    width, height = size.split('x')[0], size.split('x')[1]
                else:
                    width, height = size, None
            else:
                width, height = None, None
            
            # æ·»åŠ åŒ¹é…å‰çš„æ–‡æœ¬
            parts.append(updated_content[last_end:match['start']])

            if not resource_path:
                resource_path = note_file_path

            # å¤„ç†æœ¬åœ°èµ„æºé“¾æ¥
            if not is_web_link(resource_path) and (not resource_path.startswith('obsidian://')):
                resource_path = decode_url_space_only(resource_path)
                resource_name = os.path.basename(resource_path)
                
                # æŸ¥æ‰¾èµ„æºæ–‡ä»¶çš„ç›¸å¯¹è·¯å¾„
                resource_relpath = find_resource_file(target_note_dir, resource_path, current_note_dir)
                
                # å¦‚æœæ‰¾åˆ°èµ„æºï¼Œç”Ÿæˆå¤–éƒ¨é“¾æ¥æ ¼å¼
                if resource_relpath:
                    # è®¡ç®—ç›¸å¯¹ä»“åº“æ ¹ç›®å½•çš„è·¯å¾„
                    rel_path = resource_relpath.replace('\\', '/')  # ç»Ÿä¸€ä½¿ç”¨æ­£æ–œæ 
                    
                    # æ‹¼æ¥æˆå®Œæ•´çš„ URL
                    external_link_prefix = r'https://gitee.com/quillnk/linkres/raw/master/obsidian/'
                    full_url = f'{external_link_prefix}{rel_path}'
                    
                    if match['title'] and not match['block_id']:
                        full_url += f'#{match["title"]}'
                    # if (not match['title']) and match['block_id']:
                    #     full_url += f'#^{match["block_id"]}'
                    full_url = decode_url_space_only(full_url)
                    full_url = encode_url_space_only(full_url)
                        
                    file_type = get_file_type(resource_name)
                    
                    if file_type == 'image':
                        alt_text = desc or resource_name
                        alt_text = decode_url_space_only(alt_text)
                        if embed:
                            # ç”ŸæˆåµŒå…¥å¼å›¾ç‰‡çš„ HTML
                            if width and height:
                                full_path = f'<img src="{full_url}" width="{width}" height="{height}" alt="{alt_text}" />'
                            elif width:
                                full_path = f'<img src="{full_url}" width="{width}" alt="{alt_text}" />'
                            elif height:
                                full_path = f'<img src="{full_url}" height="{height}" alt="{alt_text}" />'
                            else:
                                full_path = f'<img src="{full_url}" alt="{alt_text}" />'
                        else:
                            # ç”Ÿæˆå›¾ç‰‡çš„ Markdown é“¾æ¥
                            if width and height:
                                full_path = f'[{alt_text}|{width}x{height}]({full_url})'
                            elif width:
                                full_path = f'[{alt_text}|{width}]({full_url})'
                            elif height:
                                full_path = f'[{alt_text}|{height}]({full_url})'
                            else:
                                full_path = f'[{alt_text}]({full_url})'  
                    elif file_type == 'audio':
                        alt_text = desc or resource_name
                        alt_text = decode_url_space_only(alt_text)
                        file_ext = resource_name.split('.')[-1]
                        if embed:
                            # ç”ŸæˆåµŒå…¥å¼éŸ³é¢‘çš„ HTML
                            full_path = f'<audio controls><source src="{full_url}" type="audio/{file_ext}">{alt_text}</audio>'
                        else:
                            # ç”ŸæˆéŸ³é¢‘çš„ Markdown é“¾æ¥
                            full_path = f'[{alt_text}]({full_url})'
                    elif file_type == 'video':
                        alt_text = desc or resource_name
                        alt_text = decode_url_space_only(alt_text)
                        file_ext = resource_name.split('.')[-1]
                        if embed:
                            # ç”ŸæˆåµŒå…¥å¼è§†é¢‘çš„ HTML
                            full_path = f'<video controls><source src="{full_url}" type="video/{file_ext}">{alt_text}</video>'
                        else:
                            # ç”Ÿæˆè§†é¢‘çš„ Markdown é“¾æ¥
                            full_path = f'[{alt_text}]({full_url})'
                    elif file_type == 'pdf':
                        alt_text = desc or resource_name
                        alt_text = decode_url_space_only(alt_text)
                        if embed:
                            # ç”ŸæˆåµŒå…¥å¼ PDF çš„ HTML
                            if width:
                                full_path = f'<embed src="{full_url}" width="{width}" type="application/pdf">'
                            elif height:
                                full_path = f'<embed src="{full_url}" height="{height}" type="application/pdf">'
                            else:
                                full_path = f'<embed src="{full_url}" type="application/pdf">'
                        else:
                            # ç”Ÿæˆ PDF çš„ Markdown é“¾æ¥
                            full_path = f'[{alt_text}]({full_url})'   
                    else:
                        # # å…¶å®ƒæ–‡ä»¶ç±»å‹ç”Ÿæˆ Markdown é“¾æ¥
                        # display_text = desc or title or block_id or resource_name
                        # display_text = decode_url_space_only(display_text)
                        # if embed:
                        #     full_path = f'![{display_text}]({full_url})'
                        # else:
                        #     full_path = f'[{display_text}]({full_url})'    
                        
                        full_path = match['full_match']
                        
                else:
                    full_path = match['full_match']
                    logger.warning(f"âš ï¸ è­¦å‘Š: èµ„æºæœªæ‰¾åˆ°ï¼š {resource_path}")
                    logger.warning(f"ğŸ“ åœ¨ç¬”è®°ä¸­: {note_file_path}")
                    logger.warning(f"â© ä¿ç•™åŸå§‹é“¾æ¥ï¼š{full_path}")
            
            else:
                full_path = match['full_match']
 
            # æ·»åŠ åŒ¹é…åˆ°çš„é“¾æ¥åˆ°å†…å®¹ç‰‡æ®µ
            parts.append(full_path)
            last_end = match['end']
            
        # æ·»åŠ æœ€åä¸€ä¸ªç‰‡æ®µ
        parts.append(updated_content[last_end:])
        
        # æ‹¼æ¥æ‰€æœ‰éƒ¨åˆ†
        updated_content = ''.join(parts)
    
    return updated_content


def update_resource_links(note_file_path):
    """
    æ›´æ–°æ–‡ä»¶ä¸­çš„èµ„æºé“¾æ¥ä¸ºå¤–éƒ¨è®¿é—®é“¾æ¥
    :param note_file_path: ç¬”è®°æ–‡ä»¶è·¯å¾„
    """
    with open(note_file_path, 'r', encoding='utf-8', newline='') as file:
        try:
            content = file.read()
            # print("content[:100]:", content[:100])  # æ‰“å°å‰100ä¸ªå­—ç¬¦ä½œä¸ºæµ‹è¯•
        except IOError as e:
            print(f"IOError: {e}")
        except UnicodeDecodeError as e:
            print(f"UnicodeDecodeError: {e}")
        except Exception as e:
            print(f"Unexpected error: {e}")

    # æå–ä»£ç å†…å®¹å¹¶ç”¨å ä½ç¬¦æ›¿æ¢
    updated_content, code_blocks = save_code_blocks(content)
    
    # è½¬æ¢ä¸º Markdown é“¾æ¥æ ¼å¼
    updated_content = convert_wiki_links(note_file_path, updated_content)
    
    # è½¬æ¢ä¸º Web å¯è®¿é—®çš„é“¾æ¥æ ¼å¼
    updated_content = convert_markdown_links(note_file_path, updated_content)
    
    updated_content = convert_markdown_links_blog(note_file_path, updated_content)
    
    # æ¢å¤ä»£ç å—
    updated_content = restore_code_blocks(updated_content, code_blocks)

    with open(note_file_path, 'w', encoding='utf-8', newline='') as file:
        try:
            file.write(updated_content)
            # print(f"âœ… æˆåŠŸæ›´æ–°æ–‡ä»¶: {note_file_path}")
        except Exception as e:
            logger.error(f"âš ï¸ å†™å…¥æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯:{e}")


def iterate_files(target_note_dir):
    """éå†ç›®æ ‡ç›®å½•ä¸­çš„æ‰€æœ‰ç¬”è®°æ–‡ä»¶æ›´æ–°é“¾æ¥"""
    ignored_dirs = get_ignore_list(target_note_dir)
    updated_count = 0
    for root, dirs, files in os.walk(target_note_dir):
        # æ’é™¤ç‰¹å®šå­ç›®å½•
        dirs[:] = [d for d in dirs if d not in ignored_dirs]

        for file in files:
            if file.endswith('.md'):
                note_file_path = os.path.join(root, file)
                updated_count += 1
                logger.info(f"å¤„ç†ç¬”è®°: {note_file_path}")
                update_resource_links(note_file_path)
                
    return updated_count


def main():
    """æ‰§è¡Œæ–‡ä»¶å¤åˆ¶å’Œæ›´æ–°æ“ä½œ"""
    # ç¡®è®¤åˆ é™¤ç›®æ ‡ç›®å½•
    safe_remove_if_exists(target_note_dir)
    # åˆ›å»ºæ–°ç›®å½•
    os.makedirs(target_note_dir, exist_ok=True)

    logger.info("å¼€å§‹å¤„ç†...")
    logger.info(f"æºç›®å½•: {source_note_dir}")
    logger.info(f"ç›®æ ‡ç›®å½•: {target_note_dir}")

    # å¤åˆ¶æ–‡ä»¶ï¼ˆå¿½ç•¥ç‰¹å®šæ‰©å±•åï¼‰
    ignored_extensions = ['.tmp', '.DS_Store']
    # copy_files(source_note_dir, ignored_extensions)
    copy_files_with_timestamps(source_note_dir, ignored_extensions)

    # æ›´æ–°ç¬”è®°ä¸­çš„èµ„æºé“¾æ¥
    updated_count = iterate_files(target_note_dir)

    logger.info("\nâœ… å¤„ç†å®Œæˆï¼")
    logger.info(f"å…±å¤„ç† {updated_count} ä¸ªç¬”è®°: {target_note_dir}")


if __name__ == "__main__":
    # è®¾ç½®æ—¥å¿—çº§åˆ«
    logger.setLevel(logging.INFO)
    main()
