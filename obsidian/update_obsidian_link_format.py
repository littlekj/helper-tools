"""
éœ€æ±‚ç›®æ ‡

- å°† Markdown æ–‡ä»¶ä¸­å¼•ç”¨çš„æœ¬åœ°èµ„æºè·¯å¾„ï¼ˆå¦‚å›¾ç‰‡ã€æ–‡ä»¶ï¼‰è‡ªåŠ¨è½¬æ¢ä¸ºå¯é€šè¿‡ Web è®¿é—®çš„å¤–éƒ¨ URL æ ¼å¼

å¤„ç†èŒƒå›´

1. Obsidian ç‰¹æœ‰çš„ Wiki é“¾æ¥æ ¼å¼ï¼š
   - æ™®é€šæ–‡ä»¶é“¾æ¥ï¼š`[[æ–‡ä»¶è·¯å¾„]]`
   - å›¾ç‰‡èµ„æºé“¾æ¥ï¼š`![[å›¾ç‰‡è·¯å¾„]]`
   - æ”¯æŒå¸¦é”šç‚¹çš„é“¾æ¥ï¼š`[[æ–‡ä»¶è·¯å¾„#é”šç‚¹]]`
   - æ”¯æŒå¸¦åˆ«åçš„é“¾æ¥ï¼š`[[æ–‡ä»¶è·¯å¾„|åˆ«å]]`

2. æ ‡å‡† Markdown é“¾æ¥æ ¼å¼ï¼š
   - æ™®é€šè¶…é“¾æ¥ï¼š`[æè¿°](æ–‡ä»¶è·¯å¾„)`
   - å›¾ç‰‡é“¾æ¥ï¼š`![æè¿°](å›¾ç‰‡è·¯å¾„)`
   - æ”¯æŒå¸¦é”šç‚¹çš„é“¾æ¥ï¼š`[æè¿°](æ–‡ä»¶è·¯å¾„#é”šç‚¹)`
   - æ”¯æŒå›¾ç‰‡å°ºå¯¸å£°æ˜ï¼š`![200x300](å›¾ç‰‡.png)`

"""
import os
import shutil
import re
from urllib.parse import quote
import sys
from pathlib import Path
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
logger = logging.getLogger('ObsidianLinkConverter')

# é…ç½®è·¯å¾„
source_folder = "Default"
# source_note_dir = fr'D:\Obsidian\{source_folder}'
source_note_dir = fr'D:\Obsidian\bak\Default - origin'
target_note_dir = fr'D:\Obsidian\Middle\{source_folder}'
# new_image_dir = fr'D:\Obsidian\Middle\linkres'
# new_image_subfolder = "obsidian"
external_link_prefix = r'https://raw.githubusercontent.com/littlekj/linkres/master/obsidian/'
# external_link_prefix = '/'  # å‰ç¼€æ·»åŠ  / ç”Ÿæˆç»å¯¹è·¯å¾„ï¼Œæ‹¼æ¥ GitHub ä»“åº“åœ°å€ä¾¿äº Web è®¿é—®


# å®šä¹‰æ‰€æœ‰æ”¯æŒçš„æ–‡ä»¶ç±»å‹ï¼ˆæ‰©å±•åˆ—è¡¨ï¼‰
supported_extensions = {
    'image': ['png', 'jpg', 'jpeg', 'gif', 'bmp', 'tiff', 'webp', 'svg'],
    'document': ['pdf', 'doc', 'docx', 'xls', 'xlsx', 'ppt', 'pptx', 'txt', 'md'],
    'audio': ['mp3', 'wav', 'ogg', 'flac', 'm4a'],
    'video': ['mp4', 'mov', 'avi', 'mkv', 'webm'],
    'archive': ['zip', 'rar', '7z', 'tar', 'gz']
}

# æ„å»ºæ‰€æœ‰æ‰©å±•åçš„æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼
all_extensions = []
for category in supported_extensions.values():
    all_extensions.extend(category)
    
# åŒ¹é… Obsidian ç‰¹æœ‰çš„ Wiki é“¾æ¥æ ¼å¼
# æ ¼å¼ï¼š[[æ–‡ä»¶]] æˆ– ![[æ–‡ä»¶]]
link_regex = re.compile(
    r'(!?)\[\[([^\]\|\n#]*?)(?:#([^\]\|\n]*?))?(?:\|([^\]\|\n]*?))?(?:\|(\d+)(?:x(\d+))?)?\]\]',
    re.MULTILINE
)

# åŒ¹é…æ ‡å‡†çš„ Markdown è¶…é“¾æ¥è¯­æ³•ï¼ˆåŒ…æ‹¬å›¾ç‰‡é“¾æ¥ï¼‰
# å¦‚ [æè¿°](é“¾æ¥) æˆ– ![æè¿°](é“¾æ¥)
link_pattern = r'''
    (!)?                    # å›¾ç‰‡æ ‡è¯†ï¼ˆå¯é€‰ï¼‰
    \[                      # å¼€å§‹æ‹¬å· [
    (                       # æ•è·ç»„ï¼šé“¾æ¥æ–‡æœ¬/å›¾ç‰‡æè¿°
        (?:                 # éæ•è·ç»„ï¼ˆå¤„ç†å°ºå¯¸æˆ–åˆ«åéƒ¨åˆ†ï¼‰
            [^\]\|\n]*      # é™¤ ]ã€|ã€æ¢è¡Œå¤–çš„ä»»æ„å­—ç¬¦
            (?:\|           # åˆ†éš”ç¬¦ |ï¼ˆå¯é€‰ï¼‰
                [^\]\n]*    # é™¤ ]ã€æ¢è¡Œå¤–çš„ä»»æ„å­—ç¬¦
            )?              # åˆ†éš”ç¬¦éƒ¨åˆ†ç»“æŸ
        )                   # éæ•è·ç»„ç»“æŸ
    )                       # æ•è·ç»„ç»“æŸ
    \]                      # ç»“æŸæ‹¬å· ]
    \(                      # å¼€å§‹æ‹¬å· (
    (                       # æ•è·ç»„ï¼šURL/è·¯å¾„
        (?:                 # å…è®¸æ‹¬å·å‡ºç°åœ¨URLä¸­
            [^()\n]         # éæ‹¬å·å­—ç¬¦
            |               # æˆ–
            \([^()\n]*\)    # æˆå¯¹çš„æ‹¬å·å†…å®¹
        )*                  # é‡å¤å¤šæ¬¡
        [^)\n]*             # æœ€åå¯ä»¥æœ‰ä¸€äº›éæ‹¬å·å­—ç¬¦
    )                       # URLæ•è·ç»„ç»“æŸ
    \)                      # ç»“æŸæ‹¬å· )
'''

compiled_pattern = re.compile(link_pattern, re.VERBOSE)


# ä»£ç å—åŒ¹é…æ­£åˆ™ï¼ˆåŒæ—¶åŒ¹é…å¤šè¡Œä»£ç å—å’Œå•è¡Œå†…è”ä»£ç ï¼‰
code_pattern = re.compile(
    r'(?s)(```.*?```|~~~.*?~~~|`[^`]+?`)',
    re.DOTALL
)

# å…¨å±€èµ„æºç¼“å­˜ï¼ˆé¿å…é‡å¤æŸ¥æ‰¾ï¼‰
resource_cache = {}

def confirm_delete(path):
    """ç¡®è®¤æ˜¯å¦åˆ é™¤æŒ‡å®šè·¯å¾„"""
    confirm = input(f"âš ï¸  ç¡®è®¤åˆ é™¤å†…å®¹ï¼š{path}ï¼Ÿ(y/N): ").strip().lower()
    return confirm == 'y'    

def remove_if_exists(path):
    """åˆ é™¤æ–‡ä»¶æˆ–ç›®å½•ï¼Œå¦‚æœå­˜åœ¨"""
    if os.path.exists(path):
        if os.path.isfile(path):
            os.remove(path)
        elif os.path.isdir(path):
            shutil.rmtree(path)
        logger.info(f"å·²åˆ é™¤: {path}")

def safe_remove_if_exists(path):
    """å®‰å…¨åˆ é™¤ç›®å½•ï¼Œå…ˆç¡®è®¤å†æ‰§è¡Œ"""
    if confirm_delete(path):
        remove_if_exists(path)
    else:
        print("âŒ å·²å–æ¶ˆåˆ é™¤æ“ä½œã€‚") 
        sys.exit(1)  # ç«‹å³é€€å‡ºç¨‹åº

# ç¡®è®¤åˆ é™¤ç›®æ ‡ç›®å½•
safe_remove_if_exists(target_note_dir)
# safe_remove_if_exists(new_image_dir)

# åˆ›å»ºæ–°ç›®å½•
os.makedirs(target_note_dir, exist_ok=True)
# os.makedirs(new_image_dir, exist_ok=True)


def copy_files(source_note_dir, ignored_extensions=None):
    """å¤åˆ¶æºç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶åˆ°ç›®æ ‡ç›®å½•"""
    ignored_extensions = ignored_extensions or []
    for item in os.listdir(source_note_dir):
        source_path = os.path.join(source_note_dir, item)
        destination_path = os.path.join(target_note_dir, item)

        # è·³è¿‡å¿½ç•¥çš„æ–‡ä»¶ç±»å‹
        if any(source_path.endswith(ext) for ext in ignored_extensions):
            continue

        # # è·³è¿‡ç‰¹å®šç³»ç»Ÿæ–‡ä»¶
        # if item.startswith('.') or item in ['Thumbs.db', 'desktop.ini']:
        #     continue

        remove_if_exists(destination_path)
        if os.path.isdir(source_path):
            shutil.copytree(source_path, destination_path, dirs_exist_ok=True)
            logger.info(f"å¤åˆ¶ç›®å½•: {source_path} -> {destination_path}")
        else:
            shutil.copy2(source_path, destination_path)
            logger.info(f"å¤åˆ¶æ–‡ä»¶: {source_path} -> {destination_path}")


def get_ignore_list(target_dir):
    """è·å–å¿½ç•¥æ–‡ä»¶åˆ—è¡¨"""
    ignore_files_path = os.path.join(target_dir, '.gitignore')
    if not os.path.exists(ignore_files_path):
        return []

    ignored = []
    with open(ignore_files_path, 'r', encoding='utf-8', newline='') as f:
        for line in f:
            stripped_line = line.strip()
            if stripped_line and not stripped_line.startswith('#'):
                # å¤„ç†ç›®å½•å¿½ç•¥ï¼ˆç§»é™¤ç»“å°¾çš„/ï¼‰
                if stripped_line.endswith('/'):
                    stripped_line = stripped_line[:-1]
                ignored.append(stripped_line)
    return ignored


def iterate_files(target_note_dir):
    """éå†ç›®æ ‡ç›®å½•ä¸­çš„æ‰€æœ‰ç¬”è®°æ–‡ä»¶æ›´æ–°é“¾æ¥"""
    ignored_dirs = get_ignore_list(target_note_dir)
    updated_count = 0
    for root, dirs, files in os.walk(target_note_dir):
        # æ’é™¤ç‰¹å®šå­ç›®å½•
        dirs[:] = [d for d in dirs if d not in ignored_dirs]

        for file in files:
            if file.endswith('.md'):
                note_file_path = os.path.join(root, file)
                updated_count += 1
                logger.info(f"å¤„ç†ç¬”è®°: {note_file_path}")
                update_resource_links(note_file_path)
                
    return updated_count

    
def find_resource_file(source_dir, resource_path, current_note_dir):
    """
    åœ¨ä»“åº“ä¸­æŸ¥æ‰¾èµ„æºæ–‡ä»¶
    :param source_dir: ä»“åº“æ ¹ç›®å½•
    :param resource_path: èµ„æºè·¯å¾„ï¼ˆå¯èƒ½åŒ…å«ç›¸å¯¹è·¯å¾„ï¼‰
    :param current_note_dir: å½“å‰ç¬”è®°æ‰€åœ¨ç›®å½•
    :return: åŸºäºä»“åº“æ ¹ç›®å½•çš„ç›¸å¯¹è·¯å¾„ï¼Œå¦‚æœæ‰¾ä¸åˆ°è¿”å›None
    """
    # è½¬æ¢URLç¼–ç çš„ç©ºæ ¼ä¸ºæ™®é€šç©ºæ ¼
    resource_path = decode_url_space_only(resource_path)

    # æ£€æŸ¥ç¼“å­˜
    cache_key = (resource_path, current_note_dir)
    if cache_key in resource_cache:
        return resource_cache[cache_key]

    # å°è¯•å¯èƒ½çš„è·¯å¾„ç»„åˆ
    possible_paths = []

    # ç›¸å¯¹äºå½“å‰ç¬”è®°çš„è·¯å¾„
    relative_to_note = os.path.join(current_note_dir, resource_path)
    possible_paths.append(relative_to_note)
    
    # ç›¸å¯¹äºä»“åº“æ ¹ç›®å½•çš„è·¯å¾„
    relative_to_root = os.path.join(source_dir, resource_path)
    possible_paths.append(relative_to_root)
    
    # å°è¯•è§£æç»å¯¹è·¯å¾„ï¼ˆä»¥ / å¼€å¤´ï¼‰
    if resource_path.startswith('/'):
        abs_path = os.path.abspath(os.path.join(source_dir, resource_path[1:]))
        possible_paths.append(abs_path)
        
    # å°è¯•è§£æç›¸å¯¹è·¯å¾„ï¼ˆä»¥ ./ æˆ– ../ å¼€å¤´ï¼‰
    elif resource_path.startswith(('./', '../')):
        abs_path = os.path.abspath(os.path.join(current_note_dir, resource_path))

        # ç¡®ä¿è·¯å¾„åœ¨ä»“åº“æ ¹ç›®å½•å†…
        if not abs_path.startswith(os.path.abspath(source_dir)):
            logger.warning(f"èµ„æºè·¯å¾„è¶…å‡ºä»“åº“èŒƒå›´ï¼š{abs_path}")
            resource_cache[cache_key] = None
            return None

        possible_paths.append(abs_path)
        
    # å°è¯•è§£æå…¶ä»–ç›¸å¯¹è·¯å¾„
    else:
        # å°è¯•ç›¸å¯¹äºå½“å‰ä»“åº“çš„ç›¸å¯¹è·¯å¾„
        direct_path = os.path.normpath(os.path.join(source_dir, resource_path))
        possible_paths.append(direct_path)
        
        # å°è¯•ç›¸å¯¹äºå½“å‰ç¬”è®°çš„éšå¼ç›¸å¯¹è·¯å¾„
        abs_path = os.path.normpath(os.path.join(current_note_dir, resource_path))
        possible_paths.append(abs_path)
        
    for path in possible_paths:
        # åˆ¤æ–­è·¯å¾„æ˜¯å¦ä¸ºæ–‡ä»¶
        if os.path.isfile(path):
            rel_path = os.path.relpath(path, source_dir)
            resource_cache[cache_key] = rel_path
            return rel_path
        # æ–‡ä»¶åå½¢å¦‚ï¼šfile.ext.extï¼Œä½†æ’å…¥çš„å¯èƒ½æ˜¯ file.ext
        # å°è¯•ç›´æ¥æ·»åŠ æ‰©å±•å
        else:
            for ext in all_extensions:
                extended_path = f"{path}.{ext}"
                if os.path.isfile(extended_path):
                    rel_path = os.path.relpath(extended_path, source_dir)
                    resource_cache[cache_key] = rel_path
                    return rel_path

    # å°è¯•å…¨åº“æ–‡ä»¶åæœç´¢     
    filename = os.path.basename(resource_path)
    for root, _, files in os.walk(source_dir):
        for file in files:
            # åŒ¹é…æ–‡ä»¶åï¼ˆå¸¦æ‰©å±•åæˆ–ä¸å¸¦æ‰©å±•åï¼‰
            if file == filename or any(file == f"{filename}.{ext}" for ext in all_extensions):
                file_path = os.path.join(root, file)
                if os.path.isfile(file_path):
                    rel_path = os.path.relpath(file_path, source_dir)
                    resource_cache[cache_key] = rel_path
                    return rel_path

    # æœªæ‰¾åˆ°èµ„æº
    resource_cache[cache_key] = None
    return None

def get_file_type(file_path):
    """æ ¹æ®æ–‡ä»¶æ‰©å±•åè·å–æ–‡ä»¶ç±»å‹"""
    ext = file_path.split('.')[-1].lower() if '.' in file_path else ''
    for file_type, extensions in supported_extensions.items():
        if ext in extensions:
            return file_type
    return 'other'


def save_code_blocks(content):
    """
    æå–æ‰€æœ‰ä»£ç å—å’Œå†…è”ä»£ç ï¼Œå¹¶ç”¨å ä½ç¬¦æ›¿ä»£
    """
    # æå–æ‰€æœ‰ä»£ç å—å’Œå†…è”ä»£ç 
    code_blocks = code_pattern.findall(content)
    
    # ç”¨å ä½ç¬¦æ›¿ä»£ä»£ç å—å’Œå†…è”ä»£ç 
    content = code_pattern.sub('__CODE_BLOCK__', content)

    return content, code_blocks


def restore_code_blocks(content, code_blocks):
    """
    æŒ‰é¡ºåºå°†å ä½ç¬¦æ›¿æ¢å›ä»£ç å—å’Œå†…è”ä»£ç 
    """
    for code_block in code_blocks:
        content = content.replace('__CODE_BLOCK__', code_block, 1)
    return content


def encode_url_space_only(url):
    """
    ä»…å¯¹URLä¸­çš„ç©ºæ ¼è¿›è¡Œç¼–ç 
    """
    return url.replace(" ", "%20")

def decode_url_space_only(url):
    """
    ä»…å¯¹URLä¸­çš„ç©ºæ ¼è¿›è¡Œè§£ç 
    """
    return url.replace("%20", " ")


def extract_resource_links(content):
    """
    æå–ç¬”è®°ä¸­èµ„æºçš„é“¾æ¥
    """
    matches = []
    for match in compiled_pattern.finditer(content):
        is_image = match.group(1) is not None
        link_text = match.group(2)
        url = match.group(3).strip()  # å»é™¤é¦–å°¾ç©ºæ ¼
        url = decode_url_space_only(url)
        size_info = None
        alt_text = link_text
        
        if is_image:
            if re.match(r'^\d+$', link_text):
                width = link_text.split('x')
                size_info = f"width={width}"
                
            elif re.match(r'^\d+x\d+$', link_text):
                width, height = link_text.split('x')
                size_info = f"width={width}, height={height}"
                
            elif '|' in link_text:
                parts = link_text.split('|', 1)
                alt_text = parts[0]
                size_part = parts[1]
                
                if re.match(r'^\d+x\d+$', size_part):
                    width, height = size_part.split('x')
                    size_info = f"width={width}, height={height}"
                elif re.match(r'^\d+$', size_part):
                    size_info = f"width={size_part}"
                    
        match_info = {
            'type': 'image' if is_image else 'link',
            'full_match': match.group(0),
            'text': alt_text,
            'url': url,
            'size': size_info,
            'start': match.start(),
            'end': match.end()
        }
        matches.append(match_info)
        
    return matches

def is_web_link(link):
    """
    åˆ¤æ–­é“¾æ¥æ˜¯å¦ä¸ºç½‘é¡µé“¾æ¥
    """
    # 1. å¦‚æœä»¥http://æˆ–https://å¼€å¤´
    if link.startswith(('http://', 'https://')):
        return True
    
    # 2. å¸¸è§ç½‘ç»œåè®®
    if link.startswith(('ftp://', 'mailto:', 'tel:')):
        return True
    
    # 3. æ ‡å‡†URLæ ¼å¼ï¼ˆå¸¦åŸŸåï¼‰
    domain_pattern = re.compile(
        r'^(?:[a-zA-Z0-9-]+\.)+[a-zA-Z]{2,}'  # åŸŸå
        r'(?::\d+)?'  # ç«¯å£
        r'(?:/[^\s]*)?$'  # è·¯å¾„
    )
    if domain_pattern.match(link):
        return True
    
    # 4. åè®®ç›¸å¯¹URLï¼ˆè§†ä¸ºå¤–éƒ¨é“¾æ¥ï¼‰
    if link.startswith('//'):
        return True
    
    # 5. æœ¬åœ°ç½‘ç»œåœ°å€ï¼ˆè§†ä¸ºæœ¬åœ°é“¾æ¥ï¼‰
    if 'localhost' in link.lower() or '127.0.0.1' in link.lower():
        return False
    
    # 6. å…¶ä»–æƒ…å†µè§†ä¸ºæœ¬åœ°é“¾æ¥
    return False

def convert_obsidian_wiki_links(note_file_path, content):
    """
    å°† Obsidian çš„ wiki é“¾æ¥è½¬æ¢ä¸ºæ ‡å‡† Markdown é“¾æ¥æ ¼å¼
    """
    # å½“å‰ç¬”è®°æ‰€åœ¨ç›®å½•
    current_note_dir = os.path.dirname(note_file_path)

    def replacement(match):
        """å¤„ç†æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…çš„èµ„æºé“¾æ¥"""
        full_match = match.group(0)  # å®Œæ•´åŒ¹é…
        sign = match.group(1)  # åŒ¹é…å¼€å¤´çš„ !ï¼ˆå¯é€‰ï¼‰
        resource_path = match.group(2)  # èµ„æºè·¯å¾„ï¼ˆå¯èƒ½ä¸ºç©ºï¼‰
        anchor = match.group(3) if match.group(3) else ''  # é”šç‚¹ï¼ˆå¯é€‰ï¼‰
        alias_or_param = match.group(4) if match.group(4) else ''  # åˆ«åæˆ–å‚æ•°ï¼ˆå¯é€‰ï¼‰
        width = match.group(5) if match.group(5) else ''  # å›¾ç‰‡å®½åº¦ï¼ˆå¯é€‰ï¼‰
        height = match.group(6) if match.group(6) else ''  # å›¾ç‰‡é«˜åº¦ï¼ˆå¯é€‰ï¼‰
        
        # å½¢å¦‚ï¼š[[#æ ‡é¢˜|è§ä¸Šæ–‡]]ï¼Œæ–‡ä»¶å†…ä¸Šä¸‹æ–‡çš„é“¾æ¥
        if not resource_path:
            resource_path = note_file_path

        resource_name = os.path.basename(resource_path)
        resource_relpath = find_resource_file(target_note_dir, resource_path, current_note_dir)

        if not resource_relpath:
            logger.warning(f"âš ï¸ è­¦å‘Š: èµ„æºæœªæ‰¾åˆ°ï¼š {resource_path}")
            logger.warning(f"ğŸ“ åœ¨ç¬”è®°ä¸­: {note_file_path}")
            logger.warning("â© è·³è¿‡æ­¤èµ„æºé“¾æ¥")
            return full_match  # ä¿ç•™åŸå§‹é“¾æ¥

        # è®¡ç®—ç›¸å¯¹ä»“åº“æ ¹ç›®å½•çš„è·¯å¾„
        rel_path = resource_relpath.replace('\\', '/')  # ç»Ÿä¸€ä½¿ç”¨æ­£æ–œæ 

        # ç”Ÿæˆå¤–éƒ¨é“¾æ¥æ ¼å¼
        # encode_path = quote(rel_path, encoding='utf-8')
        # external_link = f'{external_link_prefix}{rel_path}'
        external_link = f'{rel_path}'

        # æ·»åŠ é”šç‚¹ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if anchor:
            # encoded_anchor = quote(anchor, encoding='utf-8')
            external_link += f'#{anchor}'
        
        # å¯¹ç©ºæ ¼è¿›è¡Œç¼–ç 
        external_link = encode_url_space_only(external_link)
        
        # è·å–æ–‡ä»¶ç±»å‹
        file_type = get_file_type(resource_path)

        # æ ¹æ®æ–‡ä»¶ç±»å‹æ„å»ºä¸åŒçš„é“¾æ¥
        if file_type == 'image':
            # å›¾ç‰‡å¤„ç†ï¼šæ”¯æŒå°ºå¯¸å‚æ•°
            alt_text = alias_or_param or resource_name
            if width and height:
                return f'<img src="{external_link}" width="{width}" height="{height}" alt="{alt_text}" />'
            elif width:
                return f'<img src="{external_link}" width="{width}" alt="{alt_text}" />'
            elif height:
                return f'<img src="{external_link}" height="{height}" alt="{alt_text}" />'
            else:
                return f'![{alt_text}]({external_link})'
        else:
            # å…¶ä»–æ–‡ä»¶ç±»å‹å¤„ç†ï¼šæ”¯æŒåˆ«å
            display_text = alias_or_param or anchor or resource_name
            if full_match.startswith('!'):
                return f'![{display_text}]({external_link})'
            return f'[{display_text}]({external_link})'

    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æ›¿æ¢èµ„æºé“¾æ¥
    updated_content = link_regex.sub(replacement, content)
    
    return updated_content
    

def convert_standard_markdown_links(note_file_path, content):
    """
    å°†æ ‡å‡† Markdown é“¾æ¥è½¬æ¢ä¸º Web å¯è®¿é—®çš„å¤–éƒ¨é“¾æ¥æ ¼å¼
    """
    # å½“å‰ç¬”è®°æ‰€åœ¨ç›®å½•
    current_note_dir = os.path.dirname(note_file_path)
    
    # æå–æ‰€æœ‰èµ„æºé“¾æ¥å’Œå›¾ç‰‡åŒ¹é…é¡¹
    matches = extract_resource_links(content)
    
    # æŒ‰èµ·å§‹ä½ç½®æ­£å‘æ’åº
    matches.sort(key=lambda m: m['start'])
    
    # ä½¿ç”¨åˆ—è¡¨æ‹¼æ¥æ„å»ºæ–°å†…å®¹
    parts = []
    last_end = 0  # è®°å½•ä¸Šæ¬¡å¤„ç†ç»“æŸä½ç½®
    
    for match in matches:
        full_match = match['full_match']  # å®Œæ•´åŒ¹é…
        type = match['type']  # é“¾æ¥ç±»å‹ï¼ˆlink æˆ– imageï¼‰
        text = match['text']  # é“¾æ¥æ–‡æœ¬
        url = match['url']  # é“¾æ¥åœ°å€
        size = match['size']  # å°ºå¯¸ä¿¡æ¯
        start = match['start']  # èµ·å§‹ä½ç½®
        end = match['end']  # ç»“æŸä½ç½®
        
        # æ·»åŠ åŒ¹é…å‰çš„æ–‡æœ¬
        parts.append(content[last_end:start])
        
        # é»˜è®¤ä¿ç•™åŸå§‹é“¾æ¥
        replacement_str = full_match
        
        # å¤„ç†æœ¬åœ°èµ„æºé“¾æ¥
        if not is_web_link(url):
            resource_relpath = None
            anchor = None
            
            # æœ¬åœ°å¯èƒ½å­˜åœ¨éå›¾ç‰‡æ ¼å¼ï¼š![alt text](file://path/to/file#anchor)
            # å¤„ç†å†…éƒ¨é”šç‚¹é“¾æ¥
            if url.startswith('#'):
                anchor = url[1:]
                resource_path = note_file_path
                resource_name = os.path.basename(resource_path)
                # ä½¿ç”¨å½“å‰ç¬”è®°ç›®å½•è®¡ç®—ç›¸å¯¹è·¯å¾„
                resource_relpath = os.path.relpath(resource_path, target_note_dir)
            else:  
                # å¤„ç†å¸¦é”šç‚¹çš„æ–‡ä»¶é“¾æ¥
                if '#' in url:
                    url_parts = url.split('#', 1)
                    resource_path = url_parts[0]
                    anchor = url_parts[1]
                # å¤„ç†æ™®é€šæ–‡ä»¶é“¾æ¥
                else:
                    resource_path = url
                
                resource_name = os.path.basename(resource_path)

                # æŸ¥æ‰¾èµ„æºæ–‡ä»¶çš„ç›¸å¯¹è·¯å¾„
                resource_relpath = find_resource_file(target_note_dir, resource_path, current_note_dir)
            
            # å¦‚æœæ‰¾åˆ°èµ„æºï¼Œç”Ÿæˆå¤–éƒ¨é“¾æ¥æ ¼å¼
            if resource_relpath:
                # è®¡ç®—ç›¸å¯¹ä»“åº“æ ¹ç›®å½•çš„è·¯å¾„
                rel_path = resource_relpath.replace('\\', '/')  # ç»Ÿä¸€ä½¿ç”¨æ­£æ–œæ 
                
                # è®¡ç®—å¤–éƒ¨é“¾æ¥
                extended_link = f'{external_link_prefix}{rel_path}'
                
                # å¯¹ç©ºæ ¼è¿›è¡Œç¼–ç 
                extended_link = encode_url_space_only(extended_link)
                
                # æ·»åŠ é”šç‚¹ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                if anchor:
                    encoded_anchor = encode_url_space_only(anchor)
                    extended_link += f'#{encoded_anchor}'
                
                # æ„å»ºå¤–éƒ¨é“¾æ¥å½¢å¼
                if type == 'link':
                    display_text = text or anchor or resource_name
                    replacement_str = f'[{display_text}]({extended_link})'  
                
                elif type == 'image':
                    alt_text = text or resource_name
                    if size:
                        replacement_str = f'<img src="{extended_link}" {size} alt="{alt_text}" />'
                    else:
                        replacement_str = f'![{alt_text}]({extended_link})'
                
            else:
                logger.warning(f"âš ï¸ è­¦å‘Š: èµ„æºæœªæ‰¾åˆ°ï¼š {resource_path}")
                logger.warning(f"ğŸ“ åœ¨ç¬”è®°ä¸­: {note_file_path}")
                logger.warning("â© ä¿ç•™åŸå§‹é“¾æ¥")
 
        # æ·»åŠ æ›¿æ¢åçš„å†…å®¹
        parts.append(replacement_str)
        last_end = end  # æ›´æ–°ä¸Šæ¬¡å¤„ç†ç»“æŸä½ç½®
        
    # æ·»åŠ æœ€åä¸€æ®µæ–‡æœ¬
    parts.append(content[last_end:])
    
    # æ‹¼æ¥æ‰€æœ‰éƒ¨åˆ†
    updated_content = ''.join(parts)
    
    return updated_content

def update_resource_links(note_file_path):
    """
    æ›´æ–°æ–‡ä»¶ä¸­çš„èµ„æºé“¾æ¥ä¸ºå¤–éƒ¨è®¿é—®é“¾æ¥
    :param note_file_path: ç¬”è®°æ–‡ä»¶è·¯å¾„
    """
    with open(note_file_path, 'r', encoding='utf-8', newline='') as file:
        content = file.read()

    # æå–ä»£ç å†…å®¹å¹¶ç”¨å ä½ç¬¦æ›¿æ¢
    updated_content, code_blocks = save_code_blocks(content)
    
    # è½¬æ¢ä¸ºæ ‡å‡† Markdown é“¾æ¥æ ¼å¼
    updated_content = convert_obsidian_wiki_links(note_file_path, updated_content)
    
    # è½¬æ¢ä¸º Web å¯è®¿é—®çš„å¤–éƒ¨é“¾æ¥æ ¼å¼
    updated_content = convert_standard_markdown_links(note_file_path, updated_content)
    
    # æ¢å¤ä»£ç å—
    updated_content = restore_code_blocks(updated_content, code_blocks)

    with open(note_file_path, 'w', encoding='utf-8', newline='') as file:
        file.write(updated_content)


def main():
    """æ‰§è¡Œæ–‡ä»¶å¤åˆ¶å’Œæ›´æ–°æ“ä½œ"""
    logger.info("å¼€å§‹å¤„ç†...")
    logger.info(f"æºç›®å½•: {source_note_dir}")
    logger.info(f"ç›®æ ‡ç›®å½•: {target_note_dir}")

    # å¤åˆ¶æ–‡ä»¶ï¼ˆå¿½ç•¥ç‰¹å®šæ‰©å±•åï¼‰
    ignored_extensions = ['.tmp', '.DS_Store']
    copy_files(source_note_dir, ignored_extensions)

    # æ›´æ–°ç¬”è®°ä¸­çš„èµ„æºé“¾æ¥
    updated_count = iterate_files(target_note_dir)

    logger.info("\nâœ… å¤„ç†å®Œæˆï¼")
    logger.info(f"å…±å¤„ç† {updated_count} ä¸ªç¬”è®°: {target_note_dir}")


if __name__ == "__main__":
    # è®¾ç½®æ—¥å¿—çº§åˆ«
    logger.setLevel(logging.INFO)
    main()
